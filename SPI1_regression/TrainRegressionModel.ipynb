{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainRegressionModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvantiShri/colab_notebooks/blob/master/SPI1_regression/TrainRegressionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r34K_qhGGgSs",
        "colab_type": "code",
        "outputId": "08523dff-1d8a-43f7-864b-ca443b09862d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "![[ -e SPI1_negatives.tsv.gz ]] || wget -O SPI1_negatives.tsv.gz http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_negatives.tsv.gz -O SPI1_negatives.tsv.gz\n",
        "![[ -e SPI1_positives_regression_labels.tsv.gz ]] || wget -O SPI1_positives_regression_labels.tsv.gz http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_positives_regression_labels.tsv.gz\n",
        "\n",
        "#download hg38 fasta file\n",
        "![[ -e hg38.fa ]] || wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz -O hg38.fa.gz\n",
        "![[ -e hg38.fa ]] || gunzip hg38.fa.gz\n",
        "\n",
        "#install pyfaidx and prepare an index for hg38.fa\n",
        "!pip install pyfaidx\n",
        "from pyfaidx import Fasta\n",
        "Fasta(\"hg38.fa\") #this will build the index if it does not exist"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-05 07:00:55--  http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_negatives.tsv.gz\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 242572693 (231M) [application/x-gzip]\n",
            "Saving to: ‘SPI1_negatives.tsv.gz’\n",
            "\n",
            "SPI1_negatives.tsv. 100%[===================>] 231.33M  5.38MB/s    in 67s     \n",
            "\n",
            "2019-09-05 07:02:02 (3.46 MB/s) - ‘SPI1_negatives.tsv.gz’ saved [242572693/242572693]\n",
            "\n",
            "--2019-09-05 07:02:03--  http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_positives_regression_labels.tsv.gz\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4179271 (4.0M) [application/x-gzip]\n",
            "Saving to: ‘SPI1_positives_regression_labels.tsv.gz’\n",
            "\n",
            "SPI1_positives_regr 100%[===================>]   3.99M  2.85MB/s    in 1.4s    \n",
            "\n",
            "2019-09-05 07:02:05 (2.85 MB/s) - ‘SPI1_positives_regression_labels.tsv.gz’ saved [4179271/4179271]\n",
            "\n",
            "--2019-09-05 07:02:06--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 983659424 (938M) [application/x-gzip]\n",
            "Saving to: ‘hg38.fa.gz’\n",
            "\n",
            "hg38.fa.gz          100%[===================>] 938.09M  20.2MB/s    in 58s     \n",
            "\n",
            "2019-09-05 07:03:05 (16.1 MB/s) - ‘hg38.fa.gz’ saved [983659424/983659424]\n",
            "\n",
            "Collecting pyfaidx\n",
            "  Downloading https://files.pythonhosted.org/packages/75/a5/7e2569527b3849ea28d79b4f70d7cf46a47d36459bc59e0efa4e10e8c8b2/pyfaidx-0.5.5.2.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyfaidx) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx) (41.2.0)\n",
            "Building wheels for collected packages: pyfaidx\n",
            "  Building wheel for pyfaidx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfaidx: filename=pyfaidx-0.5.5.2-cp36-none-any.whl size=24641 sha256=6a5fa2451e7dc3d3f717ed44610227a23fe73d31726913dca038f2b5a7744833\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/a2/b4/e242e58d23b2808e191b214067880faa46cd2341f363886e0b\n",
            "Successfully built pyfaidx\n",
            "Installing collected packages: pyfaidx\n",
            "Successfully installed pyfaidx-0.5.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fasta(\"hg38.fa\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsDv4DVlT7Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "![[ -e noheader_SPI1_negatives.tsv.gz ]] || zcat SPI1_negatives.tsv.gz | grep -v 'START' | gzip -c > noheader_SPI1_negatives.tsv.gz\n",
        "![[ -e noheader_SPI1_positives_regression_labels.tsv.gz ]] || zcat SPI1_positives_regression_labels.tsv.gz | grep -v 'START' | gzip -c > noheader_SPI1_positives_regression_labels.tsv.gz\n",
        "\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -v -w 'chr1|chr8|chr21|chr22' | gzip -c > train_SPI1_negatives.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -v -w 'chr1|chr8|chr21|chr22' | gzip -c > train_SPI1_positives_regression_labels.tsv.gz\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr1|chr8|chr21' | gzip -c > test_SPI1_coords.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr1|chr8|chr21' | gzip -c >> test_SPI1_coords.tsv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPjICRl2nA08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr1' | gzip -c > minitrain_SPI1_negatives.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr1' | gzip -c > minitrain_SPI1_positives_regression_labels.tsv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK6tRLOs9VHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "311aec70-e5b2-4d51-c4a1-1c6b93cc08a2"
      },
      "source": [
        "#num negs in validation set\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr22'  | wc -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "995472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObFSZMTJ9YBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a13acf8-64f2-43e4-e261-ccdb4072c171"
      },
      "source": [
        "#num pos in validation set\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr22' | wc -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXOt1dQB92EB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8e9e03f-882e-4e90-8c84-e5df6910805e"
      },
      "source": [
        "#combine the positives and negatives in the validation set; subsample the\n",
        "# validation set for speed of calculation\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr22' | perl -ne 'if ($.%25==0) {print $_}' | gzip -c > negsubsampled_valid.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr22' | gzip -c >> negsubsampled_valid.tsv.gz\n",
        "!zcat negsubsampled_valid.tsv.gz | wc -l"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Qs7jksBRjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf67d4c8-e870-46dc-96f4-66ec201c911b"
      },
      "source": [
        "pip install tqdm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcoIFxv5IyI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9665873c-e059-4e3d-990f-fb6e81bdfd35"
      },
      "source": [
        "!git clone https://github.com/kundajelab/seqdataloader.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'seqdataloader'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 1124 (delta 57), reused 89 (delta 31), pack-reused 1003\u001b[K\n",
            "Receiving objects: 100% (1124/1124), 3.92 MiB | 6.25 MiB/s, done.\n",
            "Resolving deltas: 100% (683/683), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCAssXO1N-Tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b9eed80-9b45-4546-91d4-a763956fc51f"
      },
      "source": [
        "%cd /content/seqdataloader\n",
        "!git checkout downsamplenegatives\n",
        "!git pull\n",
        "!pip uninstall seqdataloader\n",
        "!pip install .\n",
        "%cd /content"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/seqdataloader\n",
            "Branch 'downsamplenegatives' set up to track remote branch 'downsamplenegatives' from 'origin'.\n",
            "Switched to a new branch 'downsamplenegatives'\n",
            "Already up to date.\n",
            "\u001b[33mWARNING: Skipping seqdataloader as it is not installed.\u001b[0m\n",
            "Processing /content/seqdataloader\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (1.16.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.24.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.29.13)\n",
            "Collecting deeptools>=3.0.1 (from seqdataloader==0.126)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/16/3e1757b61db790c86d1d9cf189a80946785ee69a60648647e1a44bfe504f/deepTools-3.3.0.tar.gz (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 6.8MB/s \n",
            "\u001b[?25hCollecting pybedtools>=0.7 (from seqdataloader==0.126)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/b6/af143d5247cfe331e32c96ca92056293140eb8ce788d37842f6dcea734b4/pybedtools-0.8.0.tar.gz (12.5MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5MB 38.1MB/s \n",
            "\u001b[?25hCollecting pyBigWig>=0.3.7 (from seqdataloader==0.126)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/e2/cf945d541a10bb9c675f986d5bf0b0268544721054d17cc6260cfcfb3685/pyBigWig-0.3.17.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyfaidx in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.5.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader==0.126) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader==0.126) (2018.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (3.0.3)\n",
            "Collecting pysam>=0.14.0 (from deeptools>=3.0.1->seqdataloader==0.126)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/e7/2dab8bb0ac739555e69586f1492f0ff6bc4a1f8312992a83001d3deb77ac/pysam-0.15.3.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 34.7MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.5 (from deeptools>=3.0.1->seqdataloader==0.126)\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f3/7cfe4c616e4b9fe05540256cc9c6661c052c8a4cec2915732793b36e1843/numpydoc-0.9.1.tar.gz\n",
            "Collecting py2bit>=0.2.0 (from deeptools>=3.0.1->seqdataloader==0.126)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/bb/547a927bed736ead3dc909e1e552d57c9034bb9493eff80544c0cf6e4828/py2bit-0.3.0.tar.gz\n",
            "Requirement already satisfied: plotly>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (3.6.1)\n",
            "Collecting deeptoolsintervals>=0.1.8 (from deeptools>=3.0.1->seqdataloader==0.126)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/1f/d10d6ad23c86c62d90d867d0506881a392ec6ef06885b858eaab868dd356/deeptoolsintervals-0.1.9.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pybedtools>=0.7->seqdataloader==0.126) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx->seqdataloader==0.126) (41.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->deeptools>=3.0.1->seqdataloader==0.126) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->deeptools>=3.0.1->seqdataloader==0.126) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->deeptools>=3.0.1->seqdataloader==0.126) (2.4.2)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.8.5)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (2.10.1)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2.21.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (1.3.3)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.4.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (2.7.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.1.2)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (0.15.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.1.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (19.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (2.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.1.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2019.6.16)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.3.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.5.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (0.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (19.1.0)\n",
            "Building wheels for collected packages: seqdataloader, deeptools, pybedtools, pyBigWig, pysam, numpydoc, py2bit, deeptoolsintervals\n",
            "  Building wheel for seqdataloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqdataloader: filename=seqdataloader-0.126-cp36-none-any.whl size=27501 sha256=a736ca6a900d8551cda69e05128e410e8652ea9e91f8fccc4b3ca4fdcd6e8eda\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yxpjrksr/wheels/c2/db/13/112d41662f69fb8c7986c218293570cc1550fc21eed966e31b\n",
            "  Building wheel for deeptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeptools: filename=deepTools-3.3.0-cp36-none-any.whl size=209149 sha256=fa4c46dde363963982d8828f3b59ddfd732680e9607feb07e15d61bbe5671aa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/22/40/f5eb4ef7cb83c890596ce90260a478008adeca4e4138f64430\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.8.0-cp36-cp36m-linux_x86_64.whl size=13595502 sha256=26a78b911aeba426a6b7b198ac9da794a75dead003e201160f36e5b8986d7ba4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/62/5b/fcd4580cc7fd70075dc142673a677bed992b5217a7ce22b973\n",
            "  Building wheel for pyBigWig (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyBigWig: filename=pyBigWig-0.3.17-cp36-cp36m-linux_x86_64.whl size=176951 sha256=43af55f0f0b65378b944b0c7edacdc9fe712fdd9788042be507bcd5bf591855d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/27/2d/ac3e2e2d17894877fd3c4595ebd6fbd25ad805bfeab333f19b\n",
            "  Building wheel for pysam (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysam: filename=pysam-0.15.3-cp36-cp36m-linux_x86_64.whl size=8790245 sha256=70b27cd99d851bc69638142ab659d876a0e1a2c1bde2297654b7694c5bd0c220\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/ab/84/86ca6dda37a6fc85687b67be7345b735cd82f6584bea56f327\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.1-cp36-none-any.whl size=31872 sha256=beb36c4f2733750cacb6ff086681bf1bafdd5466f3ed04b0bd0b1d2893b1179c\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/30/d1/92a39ba40f21cb70e53f8af96eb98f002a781843c065406500\n",
            "  Building wheel for py2bit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py2bit: filename=py2bit-0.3.0-cp36-cp36m-linux_x86_64.whl size=43538 sha256=9e66ef63846b62ffe1e9877db48dc1ac895cb80f2ca82b160f1890de77b84ec8\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/66/b6/33fb9b65b31121127f1da60ca27948ecf8d4c59b0967298de8\n",
            "  Building wheel for deeptoolsintervals (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeptoolsintervals: filename=deeptoolsintervals-0.1.9-cp36-cp36m-linux_x86_64.whl size=108474 sha256=cc642734e02eec22c69f80f54d5efc80bf2a5f05a50b8c7fd327183db6b7e357\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/60/60/e513c6246f67379f6e1b8d09448cdf913bac3851f96bd42e94\n",
            "Successfully built seqdataloader deeptools pybedtools pyBigWig pysam numpydoc py2bit deeptoolsintervals\n",
            "Installing collected packages: pysam, numpydoc, pyBigWig, py2bit, deeptoolsintervals, deeptools, pybedtools, seqdataloader\n",
            "Successfully installed deeptools-3.3.0 deeptoolsintervals-0.1.9 numpydoc-0.9.1 py2bit-0.3.0 pyBigWig-0.3.17 pybedtools-0.8.0 pysam-0.15.3 seqdataloader-0.126\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQt-2mghOHu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "511b88b4-5065-43ec-8226-f8fb044bc5a4"
      },
      "source": [
        "from seqdataloader.batchproducers import coordbased\n",
        "import numpy as np\n",
        "\n",
        "regression_coordstovals = coordbased.coordstovals.lookup.SimpleLookup(\n",
        "    lookup_file=\"noheader_SPI1_positives_regression_labels.tsv.gz\")\n",
        "classification_coordstovals = coordbased.coordstovals.lookup.SimpleLookup(\n",
        "    lookup_file=\"noheader_SPI1_positives_regression_labels.tsv.gz\",\n",
        "    transformation=lambda x: 1.0 if x > 0 else 0.0)\n",
        "targets_coordstovals = coordbased.coordstovals.core.CoordsToValsJoiner(\n",
        "                        [classification_coordstovals, regression_coordstovals])\n",
        "\n",
        "input_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
        "    genome_fasta_path=\"hg38.fa\")\n",
        "\n",
        "valid_batchproducer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
        "    bed_file=\"negsubsampled_valid.tsv.gz\",\n",
        "    batch_size=64,\n",
        "    shuffle_before_epoch=False,\n",
        "    seed=None)\n",
        "\n",
        "train_batchproducer = (\n",
        "  coordbased.coordbatchproducers.DownsampleNegativesCoordsBatchProducer(\n",
        "    pos_bed_file=\"minitrain_SPI1_positives_regression_labels.tsv.gz\",\n",
        "    neg_bed_file=\"minitrain_SPI1_negatives.tsv.gz\",\n",
        "    target_proportion_positives=0.5,\n",
        "    batch_size=64,\n",
        "    shuffle_before_epoch=True,\n",
        "    seed=1234))\n",
        "\n",
        "train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "    coordsbatch_producer=train_batchproducer,\n",
        "    inputs_coordstovals=input_coordstovals,\n",
        "    targets_coordstovals=targets_coordstovals,\n",
        "    coordsbatch_transformer=\\\n",
        "      coordbased.coordbatchtransformers.ReverseComplementAugmenter())\n",
        "\n",
        "valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "    coordsbatch_producer=valid_batchproducer,\n",
        "    inputs_coordstovals=input_coordstovals,\n",
        "    targets_coordstovals=targets_coordstovals)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Reading in positive bed file\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Got 31302  coords in positive bed file\n",
            "Reading in negative bed file\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Got 4881439  coords in negative bed file\n",
            "The target proportion of positives of 0.5 requires the negative set to be subsampled by a factor of 156 which will result in a #neg of 31291\n",
            "Using an offset of  0  before striding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfL1GMYoFHyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2e72c24e-66f6-405a-bdbb-38be6ee373f8"
      },
      "source": [
        "vals = list(regression_coordstovals.lookup.values())\n",
        "from matplotlib import pyplot as plt\n",
        "plt.hist(np.array(vals).squeeze(), bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsdwkCR1DAdJUsdwkCR1DAdJUuf/ADU0yhoQ9dLeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5QkUsfPUXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d598d23-061c-4afb-d16e-816ecd47fcff"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import Callback\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.constraints import max_norm\n",
        "\n",
        "\n",
        "def predict_on_datagenerator(datagenerator, model, key=None):\n",
        "  total_positives_preds = []\n",
        "  total_positives_labels = []\n",
        "  total_negatives_preds = []\n",
        "  total_negatives_labels = []\n",
        "  for batch_num in tqdm(range(len(datagenerator))):\n",
        "    batch_inputs, batch_labels = datagenerator[batch_num]\n",
        "    batch_preds = model.predict(batch_inputs)\n",
        "    if (key is not None):\n",
        "      batch_preds = batch_preds[key]\n",
        "      batch_labels = batch_labels[key]\n",
        "    batch_preds, batch_labels = (np.squeeze(batch_preds),\n",
        "                                 np.squeeze(batch_labels))\n",
        "    assert len(batch_labels.shape)==1\n",
        "    positives_mask = batch_labels > 0.0\n",
        "    negatives_mask = positives_mask==False\n",
        "    total_positives_preds.extend(batch_preds[positives_mask])\n",
        "    total_positives_labels.extend(batch_labels[positives_mask])\n",
        "    total_negatives_preds.extend(batch_preds[negatives_mask])\n",
        "    total_negatives_labels.extend(batch_labels[negatives_mask])\n",
        "\n",
        "  total_positives_preds = np.array(total_positives_preds)\n",
        "  total_positives_labels = np.array(total_positives_labels)\n",
        "  total_negatives_preds = np.array(total_negatives_preds)\n",
        "  total_negatives_labels = np.array(total_negatives_labels)\n",
        "  \n",
        "  return (total_positives_preds, total_positives_labels,\n",
        "          total_negatives_preds, total_negatives_labels)\n",
        "\n",
        "\n",
        "class SeparatePositivesNegativesMseHistory(Callback):\n",
        "  \n",
        "  def __init__(self, datasetname, datagenerator, interval_of_evaluation):\n",
        "    self.datasetname = datasetname\n",
        "    self.datagenerator = datagenerator\n",
        "    self.interval_of_evaluation = interval_of_evaluation\n",
        "    self.batches_since_last_eval = 0\n",
        "    self.positives_mse_history = []\n",
        "    self.recentered_positives_mse_history = []\n",
        "    self.positives_spearman_history = []\n",
        "    self.auroc_history = []\n",
        "    self.negatives_mse_history = []\n",
        "    self.recentered_negatives_mse_history = []\n",
        "    \n",
        "  def on_batch_end(self, *args, **kwargs):\n",
        "    \n",
        "    self.batches_since_last_eval =(\n",
        "      (1+self.batches_since_last_eval)%self.interval_of_evaluation)\n",
        "    \n",
        "    if (self.batches_since_last_eval==0):   \n",
        "      \n",
        "      (total_positives_preds, total_positives_labels,\n",
        "        total_negatives_preds, total_negatives_labels) = (\n",
        "        predict_on_datagenerator(datagenerator=self.datagenerator,\n",
        "                                 model=self.model,\n",
        "                                 key=1))\n",
        "         \n",
        "      num_positives = len(total_positives_preds)\n",
        "      num_negatives = len(total_negatives_preds)\n",
        "      \n",
        "      positives_mse = np.mean(\n",
        "          np.square(total_positives_preds-total_positives_labels))\n",
        "      negatives_mse = np.mean(\n",
        "          np.square(total_negatives_preds-total_negatives_labels))\n",
        "      recentered_positives_mse = np.mean(\n",
        "          np.square((total_positives_preds-np.mean(total_positives_preds))\n",
        "                    -(total_positives_labels-np.mean(total_positives_labels))))\n",
        "      recentered_negatives_mse = np.mean(\n",
        "          np.square((total_negatives_preds-np.mean(total_negatives_preds))\n",
        "                    -(total_negatives_labels-np.mean(total_negatives_labels))))\n",
        "      \n",
        "      positives_spearman = spearmanr(a=total_positives_preds,\n",
        "                                     b=total_positives_labels)[0]\n",
        "      auroc = roc_auc_score(y_true=[1 for x in total_positives_preds]+\n",
        "                                   [0 for x in total_negatives_preds],\n",
        "                            y_score=list(total_positives_preds)\n",
        "                                    +list(total_negatives_preds))\n",
        "      \n",
        "      self.auroc_history.append(auroc)\n",
        "      self.positives_spearman_history.append(positives_spearman)\n",
        "      self.positives_mse_history.append(positives_mse)\n",
        "      self.recentered_positives_mse_history.append(recentered_positives_mse)\n",
        "      self.negatives_mse_history.append(negatives_mse)\n",
        "      self.recentered_negatives_mse_history.append(recentered_negatives_mse)\n",
        "\n",
        "      print(\"\\n\"+self.datasetname+\": Mean mse over\",num_positives,\n",
        "            \"positives is\",positives_mse,\n",
        "            \"recentered\",recentered_positives_mse)\n",
        "      print(self.datasetname+\": positives spearman\",positives_spearman)\n",
        "      print(self.datasetname+\": auroc\",auroc)\n",
        "      print(self.datasetname+\": Mean mse over\",num_negatives,\n",
        "            \"negatives is\",negatives_mse,\n",
        "            \"recentered\",recentered_negatives_mse)\n",
        "    \n",
        "\n",
        "class CatchOverfittingOnPositives(SeparatePositivesNegativesMseHistory):\n",
        "  \n",
        "  def __init__(self, validation_data, interval_of_evaluation, patience):\n",
        "    super(CatchOverfittingOnPositives, self).__init__(\n",
        "        datasetname=\"validation set\",\n",
        "        datagenerator=validation_data,\n",
        "        interval_of_evaluation=interval_of_evaluation)\n",
        "    self.patience = patience\n",
        "    self.rounds_waited = 0\n",
        "    self.best_positives_loss = None\n",
        "    self.best_weights = None\n",
        "    self.stopped_epoch = None\n",
        "    \n",
        "  def on_batch_end(self, *args, **kwargs):\n",
        "    \n",
        "    super(CatchOverfittingOnPositives, self).on_batch_end(*args, **kwargs)\n",
        "    if (self.batches_since_last_eval==0):  \n",
        "      auroc = self.auroc_history[-1]\n",
        "      if (self.best_positives_loss is None or\n",
        "          self.best_positives_loss <= auroc):\n",
        "        print(\"New best!\")\n",
        "        self.best_weights = self.model.get_weights()\n",
        "        self.best_positives_loss = auroc\n",
        "        self.rounds_waited = 0\n",
        "      else:\n",
        "        self.rounds_waited += 1\n",
        "        if (self.rounds_waited >= self.patience):\n",
        "          self.model.stop_training = True\n",
        "          print(\"Restoring weights from the best round\")\n",
        "          self.model.set_weights(self.best_weights)\n",
        "    \n",
        "\n",
        "def manual_mse(y_true, y_pred):\n",
        "  return K.mean(K.square(y_pred-y_true), axis=-1)\n",
        "\n",
        "def mse_on_positives(y_true, y_pred):\n",
        "  the_mask = tf.greater(y_true, 0.0)\n",
        "  masked_y_true = tf.boolean_mask(y_true, the_mask)\n",
        "  masked_y_pred = tf.boolean_mask(y_pred, the_mask)\n",
        "  return K.mean(K.square(masked_y_pred-masked_y_true),axis=-1)\n",
        "\n",
        "def mse_on_negatives(y_true, y_pred):\n",
        "  the_mask = tf.equal(y_true, 0.0)\n",
        "  masked_y_true = tf.boolean_mask(y_true, the_mask)\n",
        "  masked_y_pred = tf.boolean_mask(y_pred, the_mask)\n",
        "  return K.mean(K.square(masked_y_pred-masked_y_true),axis=-1)\n",
        "\n",
        "\n",
        "def get_model(num_conv_filters,\n",
        "              conv_filter_length,\n",
        "              pool_length_and_stride,\n",
        "              num_dense_units,\n",
        "              adam_lr):\n",
        "  input = keras.layers.Input(shape=(1000,4), name=\"sequence\")\n",
        "  conv1 = keras.layers.convolutional.Conv1D(\n",
        "              filters=num_conv_filters, kernel_size=conv_filter_length,\n",
        "              kernel_constraint=max_norm(7.0,axis=-1),\n",
        "              padding=\"same\")(input)\n",
        "  conv1batchnorm = keras.layers.normalization.BatchNormalization()(conv1)\n",
        "  conv1relu = keras.layers.core.Activation(activation=\"relu\")(conv1batchnorm)\n",
        "  conv2 = keras.layers.convolutional.Conv1D(\n",
        "              filters=num_conv_filters,\n",
        "              kernel_size=conv_filter_length,\n",
        "              padding=\"same\")(conv1relu)\n",
        "  conv2batchnorm = keras.layers.normalization.BatchNormalization()(conv2)\n",
        "  conv2relu = keras.layers.core.Activation(activation=\"relu\")(conv2batchnorm)\n",
        "  conv3 = keras.layers.convolutional.Conv1D(\n",
        "              filters=num_conv_filters,\n",
        "              kernel_size=conv_filter_length,\n",
        "              padding=\"same\")(conv2relu)\n",
        "  conv3batchnorm = keras.layers.normalization.BatchNormalization()(conv3)\n",
        "  conv3relu = keras.layers.core.Activation(activation=\"relu\")(conv3batchnorm)\n",
        "  avgpool = keras.layers.convolutional.AveragePooling1D(\n",
        "                pool_size=pool_length_and_stride,\n",
        "                strides=pool_length_and_stride)(conv3relu)\n",
        "  flatten = keras.layers.core.Flatten()(avgpool)\n",
        "  dense1 = keras.layers.core.Dense(units=num_dense_units)(flatten)\n",
        "  dense1batchnorm = keras.layers.normalization.BatchNormalization()(dense1)\n",
        "  dense1relu = keras.layers.core.Activation(activation=\"relu\")(dense1batchnorm)\n",
        "  dense1dropout = keras.layers.core.Dropout(0.2)(dense1relu)\n",
        "  \n",
        "  classif_output =\\\n",
        "    keras.layers.core.Activation(activation=\"sigmoid\",\n",
        "                                 name=\"classif_output\")(\n",
        "          keras.layers.core.Dense(units=1)(dense1dropout))\n",
        "  regression_output_premult =\\\n",
        "    keras.layers.core.Activation(activation=\"relu\")(\n",
        "          keras.layers.core.Dense(units=1)(dense1dropout))\n",
        "  regression_output = keras.layers.Multiply(name=\"regression_output\")(\n",
        "                          [classif_output, regression_output_premult])\n",
        "  \n",
        "  conv_model = keras.models.Model(inputs=input,\n",
        "                                  outputs=[classif_output, regression_output])\n",
        "  conv_model.compile(optimizer=keras.optimizers.Adam(lr=adam_lr),\n",
        "                     loss=[\"binary_crossentropy\", \"mse\"])\n",
        "  return conv_model\n",
        "\n",
        "conv_model = get_model(num_conv_filters=50,\n",
        "                       conv_filter_length=15,\n",
        "                       pool_length_and_stride=40,\n",
        "                       num_dense_units=30,\n",
        "                       adam_lr=0.0001)\n",
        "\n",
        "conv_model.summary()\n",
        "early_stopping_callback = CatchOverfittingOnPositives(\n",
        "                              validation_data=valid_batch_generator,\n",
        "                              interval_of_evaluation=len(train_batch_generator),\n",
        "                              patience=20)\n",
        "fit_history = conv_model.fit_generator(\n",
        "  #x=train_batch_generator[0][0],\n",
        "  #y=train_batch_generator[0][1],\n",
        "  generator=train_batch_generator,\n",
        "  epochs=300,\n",
        "  callbacks=[early_stopping_callback,\n",
        "             SeparatePositivesNegativesMseHistory(\n",
        "              datasetname=\"minitrain\",\n",
        "              datagenerator=train_batch_generator,\n",
        "              interval_of_evaluation=len(train_batch_generator))]\n",
        ")\n",
        "#the callback isn't triggered if the upper epoch limit is hit,\n",
        "# so make sure the set the weights from the best epoch at the end\n",
        "conv_model.set_weights(early_stopping_callback.best_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0905 07:46:45.353981 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0905 07:46:45.376100 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0905 07:46:45.378120 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0905 07:46:45.486297 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0905 07:46:45.738223 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0905 07:46:45.876590 139929457473408 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0905 07:46:45.942323 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0905 07:46:45.953413 139929457473408 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0905 07:46:45.961739 139929457473408 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "sequence (InputLayer)           (None, 1000, 4)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 1000, 50)     3050        sequence[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1000, 50)     200         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1000, 50)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 1000, 50)     37550       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1000, 50)     200         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 1000, 50)     0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 1000, 50)     37550       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1000, 50)     200         conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1000, 50)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d_1 (AveragePoo (None, 25, 50)       0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 1250)         0           average_pooling1d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 30)           37530       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 30)           120         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 30)           0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 30)           0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            31          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            31          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classif_output (Activation)     (None, 1)            0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "regression_output (Multiply)    (None, 1)            0           classif_output[0][0]             \n",
            "                                                                 activation_5[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 116,462\n",
            "Trainable params: 116,102\n",
            "Non-trainable params: 360\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "248/979 [======>.......................] - ETA: 2:02 - loss: 1.0825 - classif_output_loss: 0.6446 - regression_output_loss: 0.4379"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQDbwoZYY8pu",
        "colab_type": "text"
      },
      "source": [
        "Compare perf to models trained in the DragoNN tutorial, for context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z94HwBMMcgAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a47462c4-bac7-4d23-a13a-5aba71c5d935"
      },
      "source": [
        "![[ -e SPI1.regression.model.hdf5 ]] || wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.regression.model.hdf5 -O SPI1.regression.model.hdf5"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-04 22:59:34--  http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.regression.model.hdf5\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1709600 (1.6M)\n",
            "Saving to: ‘SPI1.regression.model.hdf5’\n",
            "\n",
            "SPI1.regression.mod 100%[===================>]   1.63M  1.91MB/s    in 0.9s    \n",
            "\n",
            "2019-09-04 22:59:35 (1.91 MB/s) - ‘SPI1.regression.model.hdf5’ saved [1709600/1709600]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgrgh_Ja1QeQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "82a9f79d-c624-4646-d3e0-f8beac14d12a"
      },
      "source": [
        "![[ -e SPI1.classification.model.hdf5 ]] || wget http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.classification.model.hdf5 -O SPI1.classification.model.hdf5"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-05 00:31:29--  http://mitra.stanford.edu/kundaje/projects/dragonn/SPI1.classification.model.hdf5\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1710232 (1.6M)\n",
            "Saving to: ‘SPI1.classification.model.hdf5’\n",
            "\n",
            "SPI1.classification 100%[===================>]   1.63M  2.43MB/s    in 0.7s    \n",
            "\n",
            "2019-09-05 00:31:30 (2.43 MB/s) - ‘SPI1.classification.model.hdf5’ saved [1710232/1710232]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyZY25Z6gT8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dropout, Reshape, Dense, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.constraints import max_norm\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "reg_model=Sequential()\n",
        "reg_model.add(Reshape((1,1000,4), input_shape=(1000,4)))\n",
        "reg_model.add(Conv2D(filters=50,kernel_size=(1,15),\n",
        "                 padding=\"same\",\n",
        "                 kernel_constraint=max_norm(7.0,axis=-1),\n",
        "                 input_shape=(1,1000,4)))\n",
        "reg_model.add(BatchNormalization(axis=-1))\n",
        "reg_model.add(Activation('relu'))\n",
        "reg_model.add(Conv2D(filters=50,\n",
        "                 kernel_size=(1,15),\n",
        "                 padding=\"same\"))\n",
        "reg_model.add(BatchNormalization(axis=-1))\n",
        "reg_model.add(Activation('relu'))\n",
        "reg_model.add(Conv2D(filters=50,\n",
        "                 kernel_size=(1,13),\n",
        "                 padding=\"same\"))\n",
        "reg_model.add(BatchNormalization(axis=-1))\n",
        "reg_model.add(Activation('relu'))\n",
        "reg_model.add(MaxPooling2D(pool_size=(1,40)))\n",
        "reg_model.add(Flatten())\n",
        "reg_model.add(Dense(50))\n",
        "reg_model.add(BatchNormalization(axis=-1))\n",
        "reg_model.add(Activation('relu'))\n",
        "reg_model.add(Dropout(0.2))\n",
        "reg_model.add(Dense(1))\n",
        "reg_model.load_weights(\"SPI1.regression.model.hdf5\")\n",
        "\n",
        "classification_model=Sequential()\n",
        "classification_model.add(Reshape((1,1000,4), input_shape=(1000,4)))\n",
        "classification_model.add(Conv2D(filters=50,kernel_size=(1,15),padding=\"same\", kernel_constraint=max_norm(7.0,axis=-1),input_shape=(1,1000,4)))\n",
        "classification_model.add(BatchNormalization(axis=-1))\n",
        "classification_model.add(Activation('relu'))\n",
        "classification_model.add(Conv2D(filters=50,kernel_size=(1,15),padding=\"same\"))\n",
        "classification_model.add(BatchNormalization(axis=-1))\n",
        "classification_model.add(Activation('relu'))\n",
        "classification_model.add(Conv2D(filters=50,kernel_size=(1,13),padding=\"same\"))\n",
        "classification_model.add(BatchNormalization(axis=-1))\n",
        "classification_model.add(Activation('relu'))\n",
        "classification_model.add(MaxPooling2D(pool_size=(1,40)))\n",
        "classification_model.add(Flatten())\n",
        "classification_model.add(Dense(50))\n",
        "classification_model.add(BatchNormalization(axis=-1))\n",
        "classification_model.add(Activation('relu'))\n",
        "classification_model.add(Dropout(0.2))\n",
        "classification_model.add(Dense(1))\n",
        "classification_model.add(Activation(\"sigmoid\"))\n",
        "classification_model.load_weights('SPI1.classification.model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD4b17w3iwu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51adf66b-f764-48c0-fe2e-51bd44ef96b3"
      },
      "source": [
        "(reg_model_valid_positives_preds,\n",
        " reg_model_valid_positives_labels,\n",
        " reg_model_valid_negatives_preds,\n",
        " reg_model_valid_negatives_labels) = predict_on_datagenerator(\n",
        "    datagenerator=valid_batch_generator,\n",
        "    model=reg_model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:40<00:00, 17.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98y1_F83yxke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4b448350-a1ca-49fa-a19d-3127536e9113"
      },
      "source": [
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "print(spearmanr(list(reg_model_valid_positives_preds),\n",
        "                list(reg_model_valid_positives_labels)))\n",
        "print(spearmanr(list(reg_model_valid_positives_preds)+list(reg_model_valid_negatives_preds),\n",
        "          list(reg_model_valid_positives_labels)+list(reg_model_valid_negatives_labels)))\n",
        "print(average_precision_score(\n",
        "  y_true=[1 for x in reg_model_valid_positives_preds]+[0 for x in reg_model_valid_negatives_preds],\n",
        "  y_score=list(reg_model_valid_positives_preds)+list(reg_model_valid_negatives_preds)))\n",
        "print(roc_auc_score(\n",
        "  y_true=[1 for x in reg_model_valid_positives_preds]+[0 for x in reg_model_valid_negatives_preds],\n",
        "  y_score=list(reg_model_valid_positives_preds)+list(reg_model_valid_negatives_preds)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpearmanrResult(correlation=0.13010048765970836, pvalue=1.5316172772967612e-24)\n",
            "SpearmanrResult(correlation=0.5330318150030029, pvalue=0.0)\n",
            "0.8152531767958435\n",
            "0.9511595861381462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmgnSzfh3dZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccaa6b05-06be-4f95-f62b-0327e49d93ac"
      },
      "source": [
        "(classification_model_valid_positives_preds,\n",
        " classification_model_valid_positives_labels,\n",
        " classification_model_valid_negatives_preds,\n",
        " classification_model_valid_negatives_labels) = predict_on_datagenerator(\n",
        "    datagenerator=valid_batch_generator,\n",
        "    model=classification_model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:39<00:00, 18.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj04U3oB4Izz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1bfd5b7a-d703-45f3-9db3-a2f1b6a6c826"
      },
      "source": [
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "print(spearmanr(list(classification_model_valid_positives_preds),\n",
        "                list(classification_model_valid_positives_labels)))\n",
        "print(spearmanr(list(classification_model_valid_positives_preds)\n",
        "                +list(classification_model_valid_negatives_preds),\n",
        "                list(classification_model_valid_positives_labels)\n",
        "                +list(classification_model_valid_negatives_labels)))\n",
        "print(average_precision_score(\n",
        "  y_true=[1 for x in classification_model_valid_positives_preds]\n",
        "         +[0 for x in classification_model_valid_negatives_preds],\n",
        "  y_score=list(classification_model_valid_positives_preds)\n",
        "          +list(classification_model_valid_negatives_preds)))\n",
        "print(roc_auc_score(\n",
        "  y_true=[1 for x in classification_model_valid_positives_preds]\n",
        "         +[0 for x in classification_model_valid_negatives_preds],\n",
        "  y_score=list(classification_model_valid_positives_preds)\n",
        "          +list(classification_model_valid_negatives_preds)))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SpearmanrResult(correlation=0.09068591811093571, pvalue=1.146530073452283e-12)\n",
            "SpearmanrResult(correlation=0.5391060587840305, pvalue=0.0)\n",
            "0.8252834433603818\n",
            "0.9565124425324061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiKjC52zXwJN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}