{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainRegressionModel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvantiShri/colab_notebooks/blob/master/SPI1_regression/TrainRegressionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r34K_qhGGgSs",
        "colab_type": "code",
        "outputId": "149deb79-ab7b-4013-ef95-2ecb84b5aca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "![[ -e SPI1_negatives.tsv.gz ]] || wget -O SPI1_negatives.tsv.gz http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_negatives.tsv.gz -O SPI1_negatives.tsv.gz\n",
        "![[ -e SPI1_positives_regression_labels.tsv.gz ]] || wget -O SPI1_positives_regression_labels.tsv.gz http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_positives_regression_labels.tsv.gz\n",
        "\n",
        "#download hg38 fasta file\n",
        "![[ -e hg38.fa ]] || wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz -O hg38.fa.gz\n",
        "![[ -e hg38.fa ]] || gunzip hg38.fa.gz\n",
        "\n",
        "#install pyfaidx and prepare an index for hg38.fa\n",
        "!pip install pyfaidx\n",
        "from pyfaidx import Fasta\n",
        "Fasta(\"hg38.fa\") #this will build the index if it does not exist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-04 17:36:02--  http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_negatives.tsv.gz\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 242572693 (231M) [application/x-gzip]\n",
            "Saving to: ‘SPI1_negatives.tsv.gz’\n",
            "\n",
            "SPI1_negatives.tsv. 100%[===================>] 231.33M  1.66MB/s    in 2m 17s  \n",
            "\n",
            "2019-09-04 17:38:19 (1.69 MB/s) - ‘SPI1_negatives.tsv.gz’ saved [242572693/242572693]\n",
            "\n",
            "--2019-09-04 17:38:20--  http://mitra.stanford.edu/kundaje/avanti/regression_labels_SPI1_GM12878/positives_in_peaks/SPI1_positives_regression_labels.tsv.gz\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4179271 (4.0M) [application/x-gzip]\n",
            "Saving to: ‘SPI1_positives_regression_labels.tsv.gz’\n",
            "\n",
            "SPI1_positives_regr 100%[===================>]   3.99M  1004KB/s    in 4.1s    \n",
            "\n",
            "2019-09-04 17:38:24 (1004 KB/s) - ‘SPI1_positives_regression_labels.tsv.gz’ saved [4179271/4179271]\n",
            "\n",
            "--2019-09-04 17:38:25--  https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 983659424 (938M) [application/x-gzip]\n",
            "Saving to: ‘hg38.fa.gz’\n",
            "\n",
            "hg38.fa.gz          100%[===================>] 938.09M  25.1MB/s    in 48s     \n",
            "\n",
            "2019-09-04 17:39:14 (19.6 MB/s) - ‘hg38.fa.gz’ saved [983659424/983659424]\n",
            "\n",
            "Collecting pyfaidx\n",
            "  Downloading https://files.pythonhosted.org/packages/75/a5/7e2569527b3849ea28d79b4f70d7cf46a47d36459bc59e0efa4e10e8c8b2/pyfaidx-0.5.5.2.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyfaidx) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx) (41.2.0)\n",
            "Building wheels for collected packages: pyfaidx\n",
            "  Building wheel for pyfaidx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfaidx: filename=pyfaidx-0.5.5.2-cp36-none-any.whl size=24641 sha256=93c4d5f246bd6eaf7850cdfa3efcccffb8b1cb0818cc8c024038b4621814a3ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/a2/b4/e242e58d23b2808e191b214067880faa46cd2341f363886e0b\n",
            "Successfully built pyfaidx\n",
            "Installing collected packages: pyfaidx\n",
            "Successfully installed pyfaidx-0.5.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Fasta(\"hg38.fa\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsDv4DVlT7Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "![[ -e noheader_SPI1_negatives.tsv.gz ]] || zcat SPI1_negatives.tsv.gz | grep -v 'START' | gzip -c > noheader_SPI1_negatives.tsv.gz\n",
        "![[ -e noheader_SPI1_positives_regression_labels.tsv.gz ]] || zcat SPI1_positives_regression_labels.tsv.gz | grep -v 'START' | gzip -c > noheader_SPI1_positives_regression_labels.tsv.gz\n",
        "\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -v -w 'chr1|chr8|chr21|chr22' | gzip -c > train_SPI1_negatives.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -v -w 'chr1|chr8|chr21|chr22' | gzip -c > train_SPI1_positives_regression_labels.tsv.gz\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr1|chr8|chr21' | gzip -c > test_SPI1_coords.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr1|chr8|chr21' | gzip -c >> test_SPI1_coords.tsv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPjICRl2nA08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr1' | gzip -c > minitrain_SPI1_negatives.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr1' | gzip -c > minitrain_SPI1_positives_regression_labels.tsv.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK6tRLOs9VHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2016696d-6677-403b-cb3b-2b1c9e2215e0"
      },
      "source": [
        "#num negs in validation set\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr22'  | wc -l"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "995472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObFSZMTJ9YBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d717e9f-2ca5-4ec0-9e44-7b6664178587"
      },
      "source": [
        "#num pos in validation set\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr22' | wc -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXOt1dQB92EB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf80e172-0fd4-41d3-e26b-94f3400a23d5"
      },
      "source": [
        "#combine the positives and negatives in the validation set; subsample the\n",
        "# validation set for speed of calculation\n",
        "!zcat noheader_SPI1_negatives.tsv.gz | egrep -w 'chr22' | perl -ne 'if ($.%25==0) {print $_}' | gzip -c > negsubsampled_valid.tsv.gz\n",
        "!zcat noheader_SPI1_positives_regression_labels.tsv.gz | egrep -w 'chr22' | gzip -c >> negsubsampled_valid.tsv.gz\n",
        "!zcat negsubsampled_valid.tsv.gz | wc -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Qs7jksBRjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf82375b-ba2a-4477-f8d8-e995799b7d0e"
      },
      "source": [
        "pip install tqdm"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcoIFxv5IyI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3fb51511-3726-496d-d899-268caf7aef76"
      },
      "source": [
        "!git clone https://github.com/kundajelab/seqdataloader.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'seqdataloader'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 1078 (delta 33), reused 58 (delta 20), pack-reused 1003\u001b[K\n",
            "Receiving objects: 100% (1078/1078), 3.90 MiB | 3.04 MiB/s, done.\n",
            "Resolving deltas: 100% (659/659), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCAssXO1N-Tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a0862d2-4e79-4bb4-ad80-8f56707e4432"
      },
      "source": [
        "%cd /content/seqdataloader\n",
        "!git checkout downsamplenegatives\n",
        "!git pull\n",
        "!pip uninstall seqdataloader\n",
        "!pip install .\n",
        "%cd /content"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/seqdataloader\n",
            "Already on 'downsamplenegatives'\n",
            "Your branch is up to date with 'origin/downsamplenegatives'.\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 7 (delta 4), reused 7 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n",
            "From https://github.com/kundajelab/seqdataloader\n",
            "   1d14e82..7ee5104  downsamplenegatives -> origin/downsamplenegatives\n",
            "Updating 1d14e82..7ee5104\n",
            "Fast-forward\n",
            " seqdataloader/batchproducers/coordbased/coordstovals/lookup.py | 7 \u001b[32m++++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 4 insertions(+), 3 deletions(-)\n",
            "Uninstalling seqdataloader-0.126:\n",
            "  Would remove:\n",
            "    /usr/local/bin/db_ingest\n",
            "    /usr/local/bin/genomewide_labels\n",
            "    /usr/local/lib/python3.6/dist-packages/seqdataloader-0.126.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/seqdataloader/batchproducers/*\n",
            "    /usr/local/lib/python3.6/dist-packages/seqdataloader/dbingest/*\n",
            "    /usr/local/lib/python3.6/dist-packages/seqdataloader/labelgen/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled seqdataloader-0.126\n",
            "Processing /content/seqdataloader\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (1.16.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.24.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.29.13)\n",
            "Requirement already satisfied: deeptools>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (3.3.0)\n",
            "Requirement already satisfied: pybedtools>=0.7 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.8.0)\n",
            "Requirement already satisfied: pyBigWig>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.3.17)\n",
            "Requirement already satisfied: pyfaidx in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.126) (0.5.5.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader==0.126) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader==0.126) (2.5.3)\n",
            "Requirement already satisfied: numpydoc>=0.5 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (0.9.1)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (3.0.3)\n",
            "Requirement already satisfied: pysam>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (0.15.3)\n",
            "Requirement already satisfied: deeptoolsintervals>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (0.1.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (1.3.1)\n",
            "Requirement already satisfied: plotly>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (3.6.1)\n",
            "Requirement already satisfied: py2bit>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.126) (0.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pybedtools>=0.7->seqdataloader==0.126) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx->seqdataloader==0.126) (41.2.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (2.10.1)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.8.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->deeptools>=3.0.1->seqdataloader==0.126) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->deeptools>=3.0.1->seqdataloader==0.126) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.2->deeptools>=3.0.1->seqdataloader==0.126) (2.4.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2.21.0)\n",
            "Requirement already satisfied: nbformat>=4.2 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.4.0)\n",
            "Requirement already satisfied: decorator>=4.0.6 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.1.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (2.1.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.9.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.1.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (2.7.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (1.1.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (0.15.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (19.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2.8)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (4.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2->plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.126) (2.6.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from packaging->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.126) (19.1.0)\n",
            "Building wheels for collected packages: seqdataloader\n",
            "  Building wheel for seqdataloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqdataloader: filename=seqdataloader-0.126-cp36-none-any.whl size=27501 sha256=76d5a56bfd18fe53f499cca7e0c7caf837327fc37de396a6ba077be6cc0c45c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6ot4cry0/wheels/c2/db/13/112d41662f69fb8c7986c218293570cc1550fc21eed966e31b\n",
            "Successfully built seqdataloader\n",
            "Installing collected packages: seqdataloader\n",
            "Successfully installed seqdataloader-0.126\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQt-2mghOHu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d628057d-c804-4715-af64-b6b916b741a7"
      },
      "source": [
        "from seqdataloader.batchproducers import coordbased\n",
        "import numpy as np\n",
        "\n",
        "labels_coordstovals = coordbased.coordstovals.lookup.SimpleLookup(\n",
        "    lookup_file=\"noheader_SPI1_positives_regression_labels.tsv.gz\")\n",
        "input_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
        "    genome_fasta_path=\"hg38.fa\")\n",
        "\n",
        "valid_batchproducer = coordbased.coordbatchproducers.SimpleCoordsBatchProducer(\n",
        "    bed_file=\"negsubsampled_valid.tsv.gz\",\n",
        "    batch_size=64,\n",
        "    shuffle_before_epoch=False,\n",
        "    seed=None)\n",
        "\n",
        "train_batchproducer = (\n",
        "  coordbased.coordbatchproducers.DownsampleNegativesCoordsBatchProducer(\n",
        "    pos_bed_file=\"minitrain_SPI1_positives_regression_labels.tsv.gz\",\n",
        "    neg_bed_file=\"minitrain_SPI1_negatives.tsv.gz\",\n",
        "    target_proportion_positives=0.5,\n",
        "    batch_size=64,\n",
        "    shuffle_before_epoch=True,\n",
        "    seed=1234))\n",
        "\n",
        "train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "    coordsbatch_producer=train_batchproducer,\n",
        "    inputs_coordstovals=input_coordstovals,\n",
        "    targets_coordstovals=labels_coordstovals,\n",
        "    coordsbatch_transformer=\\\n",
        "      coordbased.coordbatchtransformers.ReverseComplementAugmenter())\n",
        "\n",
        "valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "    coordsbatch_producer=valid_batchproducer,\n",
        "    inputs_coordstovals=input_coordstovals,\n",
        "    targets_coordstovals=labels_coordstovals)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Reading in positive bed file\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Got 31302  coords in positive bed file\n",
            "Reading in negative bed file\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Got 4881439  coords in negative bed file\n",
            "The target proportion of positives of 0.5 requires the negative set to be subsampled by a factor of 156 which will result in a #neg of 31291\n",
            "Using an offset of  0  before striding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfL1GMYoFHyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c6411197-d96c-4daa-ab94-bf3c33f0ba76"
      },
      "source": [
        "vals = list(labels_coordstovals.lookup.values())\n",
        "from matplotlib import pyplot as plt\n",
        "plt.hist(np.array(vals).squeeze(), bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsdwkCR1DAdJUsdwkCR1DAdJUuf/ADU0yhoQ9dLeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh5QkUsfPUXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03c0ac0f-a09d-492b-838e-c7704afc7886"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import Callback\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "\n",
        "def predict_on_datagenerator(datagenerator, model):\n",
        "  total_positives_preds = []\n",
        "  total_positives_labels = []\n",
        "  total_negatives_preds = []\n",
        "  total_negatives_labels = []\n",
        "  for batch_num in tqdm(range(len(datagenerator))):\n",
        "    batch_inputs, batch_labels = datagenerator[batch_num]\n",
        "    batch_preds = model.predict(batch_inputs)\n",
        "    batch_preds, batch_labels = (np.squeeze(batch_preds),\n",
        "                                 np.squeeze(batch_labels))\n",
        "    assert len(batch_labels.shape)==1\n",
        "    positives_mask = batch_labels > 0.0\n",
        "    negatives_mask = positives_mask==False\n",
        "    total_positives_preds.extend(batch_preds[positives_mask])\n",
        "    total_positives_labels.extend(batch_labels[positives_mask])\n",
        "    total_negatives_preds.extend(batch_preds[negatives_mask])\n",
        "    total_negatives_labels.extend(batch_labels[negatives_mask])\n",
        "\n",
        "  total_positives_preds = np.array(total_positives_preds)\n",
        "  total_positives_labels = np.array(total_positives_labels)\n",
        "  total_negatives_preds = np.array(total_negatives_preds)\n",
        "  total_negatives_labels = np.array(total_negatives_labels)\n",
        "  \n",
        "  return (total_positives_preds, total_positives_labels,\n",
        "          total_negatives_preds, total_negatives_labels)\n",
        "\n",
        "\n",
        "class SeparatePositivesNegativesMseHistory(Callback):\n",
        "  \n",
        "  def __init__(self, datasetname, datagenerator, interval_of_evaluation):\n",
        "    self.datasetname = datasetname\n",
        "    self.datagenerator = datagenerator\n",
        "    self.interval_of_evaluation = interval_of_evaluation\n",
        "    self.batches_since_last_eval = 0\n",
        "    self.positives_mse_history = []\n",
        "    self.recentered_positives_mse_history = []\n",
        "    self.positives_spearman_history = []\n",
        "    self.negatives_mse_history = []\n",
        "    self.recentered_negatives_mse_history = []\n",
        "    \n",
        "  def on_batch_end(self, *args, **kwargs):\n",
        "    \n",
        "    self.batches_since_last_eval =(\n",
        "      (1+self.batches_since_last_eval)%self.interval_of_evaluation)\n",
        "    \n",
        "    if (self.batches_since_last_eval==0):   \n",
        "      \n",
        "      (total_positives_preds, total_positives_labels,\n",
        "        total_negatives_preds, total_negatives_labels) = (\n",
        "        predict_on_datagenerator(datagenerator=self.datagenerator,\n",
        "                                 model=self.model))\n",
        "         \n",
        "      num_positives = len(total_positives_preds)\n",
        "      num_negatives = len(total_negatives_preds)\n",
        "      \n",
        "      positives_mse = np.mean(\n",
        "          np.square(total_positives_preds-total_positives_labels))\n",
        "      negatives_mse = np.mean(\n",
        "          np.square(total_negatives_preds-total_negatives_labels))\n",
        "      recentered_positives_mse = np.mean(\n",
        "          np.square((total_positives_preds-np.mean(total_positives_preds))\n",
        "                    -(total_positives_labels-np.mean(total_positives_labels))))\n",
        "      recentered_negatives_mse = np.mean(\n",
        "          np.square((total_negatives_preds-np.mean(total_negatives_preds))\n",
        "                    -(total_negatives_labels-np.mean(total_negatives_labels))))\n",
        "      \n",
        "      positives_spearman = spearmanr(a=total_positives_preds,\n",
        "                                     b=total_positives_labels)[0]\n",
        "      \n",
        "      self.positives_spearman_history.append(positives_spearman)\n",
        "      self.positives_mse_history.append(positives_mse)\n",
        "      self.recentered_positives_mse_history.append(recentered_positives_mse)\n",
        "      self.negatives_mse_history.append(negatives_mse)\n",
        "      self.recentered_negatives_mse_history.append(recentered_negatives_mse)\n",
        "\n",
        "      print(\"\\n\"+self.datasetname+\": Mean mse over\",num_positives,\n",
        "            \"positives is\",positives_mse,\n",
        "            \"recentered\",recentered_positives_mse)\n",
        "      print(self.datasetname+\": positives spearman\",positives_spearman)\n",
        "      print(self.datasetname+\": Mean mse over\",num_negatives,\n",
        "            \"negatives is\",negatives_mse,\n",
        "            \"recentered\",recentered_negatives_mse)\n",
        "    \n",
        "\n",
        "class CatchOverfittingOnPositives(SeparatePositivesNegativesMseHistory):\n",
        "  \n",
        "  def __init__(self, validation_data, interval_of_evaluation, patience):\n",
        "    super(CatchOverfittingOnPositives, self).__init__(\n",
        "        datasetname=\"validation set\",\n",
        "        datagenerator=validation_data,\n",
        "        interval_of_evaluation=interval_of_evaluation)\n",
        "    self.patience = patience\n",
        "    self.rounds_waited = 0\n",
        "    self.best_positives_loss = None\n",
        "    self.best_weights = None\n",
        "    self.stopped_epoch = None\n",
        "    \n",
        "  def on_batch_end(self, *args, **kwargs):\n",
        "    \n",
        "    super(CatchOverfittingOnPositives, self).on_batch_end(*args, **kwargs)\n",
        "    if (self.batches_since_last_eval==0):  \n",
        "      recentered_positives_mse = self.recentered_positives_mse_history[-1]\n",
        "      if (self.best_positives_loss is None or\n",
        "          self.best_positives_loss >= recentered_positives_mse):\n",
        "        self.best_weights = self.model.get_weights()\n",
        "        self.best_positives_loss = recentered_positives_mse\n",
        "        self.rounds_waited = 0\n",
        "      else:\n",
        "        self.rounds_waited += 1\n",
        "        if (self.rounds_waited >= self.patience):\n",
        "          self.model.stop_training = True\n",
        "          print(\"Restoring weights from the best round\")\n",
        "          self.model.set_weights(self.best_weights)\n",
        "    \n",
        "\n",
        "def manual_mse(y_true, y_pred):\n",
        "  return K.mean(K.square(y_pred-y_true), axis=-1)\n",
        "\n",
        "def mse_on_positives(y_true, y_pred):\n",
        "  the_mask = tf.greater(y_true, 0.0)\n",
        "  masked_y_true = tf.boolean_mask(y_true, the_mask)\n",
        "  masked_y_pred = tf.boolean_mask(y_pred, the_mask)\n",
        "  return K.mean(K.square(masked_y_pred-masked_y_true),axis=-1)\n",
        "\n",
        "def mse_on_negatives(y_true, y_pred):\n",
        "  the_mask = tf.equal(y_true, 0.0)\n",
        "  masked_y_true = tf.boolean_mask(y_true, the_mask)\n",
        "  masked_y_pred = tf.boolean_mask(y_pred, the_mask)\n",
        "  return K.mean(K.square(masked_y_pred-masked_y_true),axis=-1)\n",
        "\n",
        "\n",
        "def get_model(num_conv_filters,\n",
        "              conv_filter_length,\n",
        "              pool_length_and_stride,\n",
        "              num_dense_units,\n",
        "              adam_lr):\n",
        "  input = keras.layers.Input(shape=(1000,4), name=\"sequence\")\n",
        "  conv1 = keras.layers.convolutional.Conv1D(\n",
        "              filters=num_conv_filters, kernel_size=conv_filter_length,\n",
        "              padding=\"same\")(input)\n",
        "  conv1batchnorm = keras.layers.normalization.BatchNormalization()(conv1)\n",
        "  conv1relu = keras.layers.core.Activation(activation=\"relu\")(conv1batchnorm)\n",
        "  conv2 = keras.layers.convolutional.Conv1D(\n",
        "              filters=num_conv_filters,\n",
        "              kernel_size=conv_filter_length,\n",
        "              padding=\"same\")(conv1relu)\n",
        "  conv2batchnorm = keras.layers.normalization.BatchNormalization()(conv2)\n",
        "  conv2relu = keras.layers.core.Activation(activation=\"relu\")(conv2batchnorm)\n",
        "  conv3 = keras.layers.convolutional.Conv1D(\n",
        "              filters=num_conv_filters,\n",
        "              kernel_size=conv_filter_length,\n",
        "              padding=\"same\")(conv2relu)\n",
        "  conv3batchnorm = keras.layers.normalization.BatchNormalization()(conv3)\n",
        "  conv3relu = keras.layers.core.Activation(activation=\"relu\")(conv3batchnorm)\n",
        "  avgpool = keras.layers.convolutional.AveragePooling1D(\n",
        "                pool_size=pool_length_and_stride,\n",
        "                strides=pool_length_and_stride)(conv3relu)\n",
        "  flatten = keras.layers.core.Flatten()(avgpool)\n",
        "  dense1 = keras.layers.core.Dense(units=num_dense_units)(flatten)\n",
        "  dense1relu = keras.layers.core.Activation(activation=\"relu\")(dense1)\n",
        "  dense2 = keras.layers.core.Dense(units=num_dense_units)(dense1relu)\n",
        "  dense2relu = keras.layers.core.Activation(activation=\"relu\")(dense2)\n",
        "  output = keras.layers.core.Dense(units=1,\n",
        "                                   name=\"output\")(dense2relu)\n",
        "  conv_model = keras.models.Model(inputs=input, outputs=output)\n",
        "  conv_model.compile(optimizer=keras.optimizers.Adam(lr=adam_lr),\n",
        "                     loss={\"output\": \"mse\"},\n",
        "                     metrics=[mse_on_positives,\n",
        "                              mse_on_negatives,\n",
        "                              manual_mse])\n",
        "  return conv_model\n",
        "\n",
        "conv_model = get_model(num_conv_filters=30,\n",
        "                       conv_filter_length=15,\n",
        "                       pool_length_and_stride=40,\n",
        "                       num_dense_units=30,\n",
        "                       adam_lr=0.0001)\n",
        "\n",
        "conv_model.summary()\n",
        "early_stopping_callback = CatchOverfittingOnPositives(\n",
        "                              validation_data=valid_batch_generator,\n",
        "                              interval_of_evaluation=len(train_batch_generator),\n",
        "                              patience=20)\n",
        "fit_history = conv_model.fit_generator(\n",
        "  #x=train_batch_generator[0][0],\n",
        "  #y=train_batch_generator[0][1],\n",
        "  generator=train_batch_generator,\n",
        "  epochs=300,\n",
        "  callbacks=[early_stopping_callback,\n",
        "             SeparatePositivesNegativesMseHistory(\n",
        "              datasetname=\"minitrain\",\n",
        "              datagenerator=train_batch_generator,\n",
        "              interval_of_evaluation=len(train_batch_generator))]\n",
        ")\n",
        "#the callback isn't triggered if the upper epoch limit is hit,\n",
        "# so make sure the set the weights from the best epoch at the end\n",
        "conv_model.set_weights(early_stopping_callback.best_weights)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequence (InputLayer)        (None, 1000, 4)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 1000, 30)          1830      \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1000, 30)          120       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 1000, 30)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 1000, 30)          13530     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 1000, 30)          120       \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 1000, 30)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 1000, 30)          13530     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 1000, 30)          120       \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 1000, 30)          0         \n",
            "_________________________________________________________________\n",
            "average_pooling1d_5 (Average (None, 25, 30)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 750)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 30)                22530     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 52,741\n",
            "Trainable params: 52,561\n",
            "Non-trainable params: 180\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.3724 - mse_on_positives: 0.5399 - mse_on_negatives: 0.2049 - manual_mse: 0.3724"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  8  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:37<00:00, 19.39it/s]\n",
            "  0%|          | 0/979 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.41459083803529845 recentered 0.37599956260215495\n",
            "validation set: positives spearman 0.2610809876340915\n",
            "validation set: Mean mse over 39818 negatives is 0.3363331005212134 recentered 0.104417537793224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 11.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.419852476774897 recentered 0.37827315173140286\n",
            "minitrain: positives spearman 0.2768180784081128\n",
            "minitrain: Mean mse over 62584 negatives is 0.3352549019752822 recentered 0.06187160328338523\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 234s 239ms/step - loss: 0.3724 - mse_on_positives: 0.5398 - mse_on_negatives: 0.2049 - manual_mse: 0.3724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.3429 - mse_on_positives: 0.5043 - mse_on_negatives: 0.1815 - manual_mse: 0.3429Using an offset of  9  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:38<00:00, 20.53it/s]\n",
            "  0%|          | 2/979 [00:00<01:33, 10.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.5432309367385423 recentered 0.38155455299088814\n",
            "validation set: positives spearman 0.25312682537728837\n",
            "validation set: Mean mse over 39818 negatives is 0.13933169164761844 recentered 0.06641497633417535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:36<00:00, 11.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.5575368985014083 recentered 0.3791843946642904\n",
            "minitrain: positives spearman 0.2936150295867173\n",
            "minitrain: Mean mse over 62584 negatives is 0.11679816519097398 recentered 0.04976693396518148\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 232s 237ms/step - loss: 0.3428 - mse_on_positives: 0.5041 - mse_on_negatives: 0.1815 - manual_mse: 0.3428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.3252 - mse_on_positives: 0.4837 - mse_on_negatives: 0.1667 - manual_mse: 0.3252Using an offset of  10  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.67it/s]\n",
            "  0%|          | 2/979 [00:00<01:35, 10.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.6449335479748024 recentered 0.39363993760847704\n",
            "validation set: positives spearman 0.18714911722349406\n",
            "validation set: Mean mse over 39818 negatives is 0.08490415783342256 recentered 0.04826400590110953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 11.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.5861605222317117 recentered 0.3765137352868328\n",
            "minitrain: positives spearman 0.26833430065113467\n",
            "minitrain: Mean mse over 62584 negatives is 0.09139830007802452 recentered 0.0424979300251708\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 231s 236ms/step - loss: 0.3252 - mse_on_positives: 0.4837 - mse_on_negatives: 0.1666 - manual_mse: 0.3252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.3138 - mse_on_positives: 0.4715 - mse_on_negatives: 0.1560 - manual_mse: 0.3138"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  11  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:37<00:00, 19.31it/s]\n",
            "  0%|          | 1/979 [00:00<01:38,  9.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.39864208443027005 recentered 0.39403034837836204\n",
            "validation set: positives spearman 0.23390741198732298\n",
            "validation set: Mean mse over 39818 negatives is 0.3271029393585282 recentered 0.13049730382300237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 10.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.3778209170019422 recentered 0.37410073783057574\n",
            "minitrain: positives spearman 0.3176923618257737\n",
            "minitrain: Mean mse over 62584 negatives is 0.31414601170873635 recentered 0.0972863772653197\n",
            "979/979 [==============================] - 233s 238ms/step - loss: 0.3140 - mse_on_positives: 0.4719 - mse_on_negatives: 0.1560 - manual_mse: 0.3140\n",
            "Epoch 5/300\n",
            "  1/979 [..............................] - ETA: 45s - loss: 0.3328 - mse_on_positives: 0.4995 - mse_on_negatives: 0.1662 - manual_mse: 0.3328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "978/979 [============================>.] - ETA: 0s - loss: 0.3002 - mse_on_positives: 0.4541 - mse_on_negatives: 0.1462 - manual_mse: 0.3002"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  12  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.69it/s]\n",
            "  0%|          | 2/979 [00:00<01:35, 10.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.8247897266582871 recentered 0.3867424439706794\n",
            "validation set: positives spearman 0.23203428038490148\n",
            "validation set: Mean mse over 39818 negatives is 0.030911577135946125 recentered 0.02796441861663919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 11.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.7858415147343946 recentered 0.3573456177292677\n",
            "minitrain: positives spearman 0.33659111443859185\n",
            "minitrain: Mean mse over 62584 negatives is 0.024651130515595893 recentered 0.023921936999668714\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 231s 236ms/step - loss: 0.3002 - mse_on_positives: 0.4542 - mse_on_negatives: 0.1462 - manual_mse: 0.3002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.2866 - mse_on_positives: 0.4374 - mse_on_negatives: 0.1358 - manual_mse: 0.2866"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  13  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.62it/s]\n",
            "  0%|          | 1/979 [00:00<01:37,  9.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.4528219391698508 recentered 0.40929675444812086\n",
            "validation set: positives spearman 0.2263775002671138\n",
            "validation set: Mean mse over 39818 negatives is 0.18162304344981972 recentered 0.09404391211873193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:38<00:00,  9.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.3920476710820418 recentered 0.35548237120823806\n",
            "minitrain: positives spearman 0.3613019829819041\n",
            "minitrain: Mean mse over 62584 negatives is 0.15957739244903596 recentered 0.07376380331643287\n",
            "979/979 [==============================] - 233s 238ms/step - loss: 0.2867 - mse_on_positives: 0.4376 - mse_on_negatives: 0.1358 - manual_mse: 0.2867\n",
            "Epoch 7/300\n",
            "  1/979 [..............................] - ETA: 43s - loss: 0.2119 - mse_on_positives: 0.2694 - mse_on_negatives: 0.1544 - manual_mse: 0.2119"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "978/979 [============================>.] - ETA: 0s - loss: 0.2731 - mse_on_positives: 0.4191 - mse_on_negatives: 0.1270 - manual_mse: 0.2731"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  14  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:37<00:00, 19.73it/s]\n",
            "  0%|          | 1/979 [00:00<01:40,  9.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.894370610856294 recentered 0.4189257043842399\n",
            "validation set: positives spearman 0.17519966431961576\n",
            "validation set: Mean mse over 39818 negatives is 1.3272770736085289 recentered 0.39518031633699374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 10.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.9287534090403728 recentered 0.3557862367171751\n",
            "minitrain: positives spearman 0.343011202114544\n",
            "minitrain: Mean mse over 62584 negatives is 1.4866669290656165 recentered 0.23301456270514614\n",
            "979/979 [==============================] - 232s 237ms/step - loss: 0.2731 - mse_on_positives: 0.4191 - mse_on_negatives: 0.1270 - manual_mse: 0.2731\n",
            "Epoch 8/300\n",
            "  1/979 [..............................] - ETA: 47s - loss: 0.2550 - mse_on_positives: 0.4285 - mse_on_negatives: 0.0815 - manual_mse: 0.2550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "978/979 [============================>.] - ETA: 0s - loss: 0.2628 - mse_on_positives: 0.4056 - mse_on_negatives: 0.1199 - manual_mse: 0.2628"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  15  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:37<00:00, 20.18it/s]\n",
            "  0%|          | 1/979 [00:00<01:49,  8.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.4820338870489383 recentered 0.4423375990205671\n",
            "validation set: positives spearman 0.2502899889121203\n",
            "validation set: Mean mse over 39818 negatives is 0.45897703547446655 recentered 0.21630606385496282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 10.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.39654969431491155 recentered 0.35841759795876516\n",
            "minitrain: positives spearman 0.41270964860092063\n",
            "minitrain: Mean mse over 62584 negatives is 0.38253295516187374 recentered 0.15302162703190156\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 232s 237ms/step - loss: 0.2628 - mse_on_positives: 0.4056 - mse_on_negatives: 0.1199 - manual_mse: 0.2628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.2530 - mse_on_positives: 0.3908 - mse_on_negatives: 0.1151 - manual_mse: 0.2530Using an offset of  16  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.54it/s]\n",
            "  0%|          | 1/979 [00:00<01:37,  9.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.4625712718037623 recentered 0.4435843601744016\n",
            "validation set: positives spearman 0.2032284441136462\n",
            "validation set: Mean mse over 39818 negatives is 0.1958196178761262 recentered 0.10987765760425759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:37<00:00, 11.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.3321163621141795 recentered 0.3273840739981389\n",
            "minitrain: positives spearman 0.4155633324745053\n",
            "minitrain: Mean mse over 62584 negatives is 0.1853105010016543 recentered 0.0895754256566627\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 231s 236ms/step - loss: 0.2529 - mse_on_positives: 0.3907 - mse_on_negatives: 0.1151 - manual_mse: 0.2529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.2440 - mse_on_positives: 0.3778 - mse_on_negatives: 0.1101 - manual_mse: 0.2440"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  17  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.70it/s]\n",
            "  0%|          | 1/979 [00:00<01:39,  9.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.7832981962935301 recentered 0.4061137924835004\n",
            "validation set: positives spearman 0.20664819310176508\n",
            "validation set: Mean mse over 39818 negatives is 0.0298164337931958 recentered 0.027649218152397355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:36<00:00, 11.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.6268224614564022 recentered 0.30555195303991955\n",
            "minitrain: positives spearman 0.4240619705831818\n",
            "minitrain: Mean mse over 62584 negatives is 0.02403346029473822 recentered 0.022965658521954566\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 230s 235ms/step - loss: 0.2439 - mse_on_positives: 0.3777 - mse_on_negatives: 0.1101 - manual_mse: 0.2439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.2347 - mse_on_positives: 0.3628 - mse_on_negatives: 0.1065 - manual_mse: 0.2347"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of  18  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.75it/s]\n",
            "  0%|          | 1/979 [00:00<01:39,  9.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.5136363405854126 recentered 0.45173989168933526\n",
            "validation set: positives spearman 0.21129652273409566\n",
            "validation set: Mean mse over 39818 negatives is 0.13065988309509974 recentered 0.0811901231860693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:36<00:00, 11.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.34092574785518914 recentered 0.3040491882128439\n",
            "minitrain: positives spearman 0.4588771269810121\n",
            "minitrain: Mean mse over 62584 negatives is 0.10705908880641765 recentered 0.061272441166215705\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 232s 237ms/step - loss: 0.2346 - mse_on_positives: 0.3625 - mse_on_negatives: 0.1066 - manual_mse: 0.2346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/300\n",
            "978/979 [============================>.] - ETA: 0s - loss: 0.2293 - mse_on_positives: 0.3536 - mse_on_negatives: 0.1048 - manual_mse: 0.2293"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/718 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using an offset of "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/718 [00:00<01:12,  9.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 19  before striding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 718/718 [00:36<00:00, 19.67it/s]\n",
            "  0%|          | 2/979 [00:00<01:34, 10.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation set: Mean mse over 6127 positives is 0.562526922092955 recentered 0.5003445339768093\n",
            "validation set: positives spearman 0.22232512229473775\n",
            "validation set: Mean mse over 39818 negatives is 0.45326627121330576 recentered 0.2186204521577894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 979/979 [01:38<00:00, 11.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "minitrain: Mean mse over 62604 positives is 0.4156877630138549 recentered 0.32110311456643303\n",
            "minitrain: positives spearman 0.47898913306406393\n",
            "minitrain: Mean mse over 62584 negatives is 0.3930797993261374 recentered 0.1606564690274058\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r979/979 [==============================] - 232s 237ms/step - loss: 0.2293 - mse_on_positives: 0.3537 - mse_on_negatives: 0.1048 - manual_mse: 0.2293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/300\n",
            "150/979 [===>..........................] - ETA: 1:20 - loss: 0.2254 - mse_on_positives: 0.3463 - mse_on_negatives: 0.1045 - manual_mse: 0.2254"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-70b154c795d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m               \u001b[0mdatasetname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minitrain\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m               \u001b[0mdatagenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batch_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m               interval_of_evaluation=len(train_batch_generator))]\n\u001b[0m\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    203\u001b[0m \u001b[0;31m#the callback isn't triggered if the upper epoch limit is hit,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z94HwBMMcgAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkRn8FpqFGUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "c8488c05-2e83-4882-beb7-057a3755dde8"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(np.arange(len(early_stopping_callback.recentered_positives_mse_history)),\n",
        "         early_stopping_callback.recentered_positives_mse_history)\n",
        "plt.plot(np.arange(len(early_stopping_callback.recentered_positives_mse_history)),\n",
        "         early_stopping_callback.recentered_negatives_mse_history)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f76e04584a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiKjC52zXwJN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}