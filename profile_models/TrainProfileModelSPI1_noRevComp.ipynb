{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainProfileModelSPI1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvantiShri/colab_notebooks/blob/master/profile_models/TrainProfileModelSPI1_noRevComp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaABrjWNwlq3",
        "colab_type": "code",
        "outputId": "f01275c0-ab54-49cc-fd0c-9643d9d62fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "![[ -f rep1.bam ]] || wget https://www.encodeproject.org/files/ENCFF724WMD/@@download/ENCFF724WMD.bam -O rep1.bam\n",
        "![[ -f rep2.bam ]] || wget https://www.encodeproject.org/files/ENCFF482TVZ/@@download/ENCFF482TVZ.bam -O rep2.bam  \n",
        "![[ -f control.bam ]] || wget https://www.encodeproject.org/files/ENCFF857FLV/@@download/ENCFF857FLV.bam -O control.bam\n",
        "![[ -f peaks.bed.gz ]] || wget https://www.encodeproject.org/files/ENCFF744AGB/@@download/ENCFF744AGB.bed.gz -O peaks.bed.gz\n",
        "\n",
        "#Get hg38 fasta by download 2bit and then converting to fa\n",
        "![[ -f hg38.2bit ]] || wget http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.2bit -O hg38.2bit  \n",
        "![[ -f twoBitToFa ]] || wget http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa -O twoBitToFa\n",
        "!chmod a+x twoBitToFa\n",
        "![[ -f hg38.genome.fa ]] || ./twoBitToFa hg38.2bit hg38.genome.fa\n",
        "\n",
        "![[ -f hg38.chrom.sizes ]] || wget https://raw.githubusercontent.com/ENCODE-DCC/encValData/master/GRCh38/GRCh38_EBV.chrom.sizes -O hg38.chrom.sizes\n",
        "![[ -f bedGraphToBigWig ]] || wget http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/bedGraphToBigWig\n",
        "!chmod a+x bedGraphToBigWig"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-10 00:50:27--  https://www.encodeproject.org/files/ENCFF724WMD/@@download/ENCFF724WMD.bam\n",
            "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
            "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://encode-public.s3.amazonaws.com/2016/12/11/5376e85f-a7ae-42d5-bc80-b478904eadf4/ENCFF724WMD.bam?response-content-disposition=attachment%3B%20filename%3DENCFF724WMD.bam&AWSAccessKeyId=ASIATGZNGCNX6CTJA57G&Signature=Pu%2B2WKGG8E%2BwIvOpSTrfmB4URDY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCgbakfHzdOn26eGc%2BbP6pHZ6epdu8YaQOGmW3%2BvZ8eXAIhAKattsGFeQZj2Fl4BQZjwMVrRpiJpsyfLoy823kdK2bwKr0DCPr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMMjIwNzQ4NzE0ODYzIgxLUr5hvXcd83B5SOsqkQM%2FVrFf3%2BuH9qAlf5tsNqbr1GSNO%2BA0%2FJNx2yy2DkS16zNePxhzE3FzT%2FIiyqHURPlTQgTAQseDhjEeIQur71IXL%2BHI%2BI7pmQ6ucowOIGvC2rCivPi4Zky5vYRfJM%2BAkHqfjC6MU34y5cW9L3g11FJ%2Fr5nE7%2BEjB5AvqVl0tiBBwYBveZPI8ggih%2F6MG310L%2BhqB1wLrAT5x%2BQ9mtYQ3klBAd2f%2F0yrgB7KeLX5brCDf8GIJ0cc5R8dXfuaSODbDYOcbm%2F7EuJe2cwsnv9bAykFM3FQeyg29w6r6BnhdmwR9KfaBJRf1nWiN5cK5Lxd0IDTW7GWpfnftcVtYnF5t5kL3nrjfhQ%2FyoP0LYDF2uZJTPyk%2BxDt4mPKLUmK6ucYKy34bzvmR%2BGPJ8G2BJItXXPsKUQsIOjuc8651vUxXlPk%2Fa%2FpqPV6TYslnr9bManb7rZomJp7tVHQhQVGsfXWJ%2Fus0JGp%2FmecP8UaEOkdC8XtZJk6s23ebqbuRm9%2FIWZGcFcUK75TILIXB%2FcJ0Y2zDV0OhDCshL%2F0BTrqAbT7ZNH50Ku8ja15eJjdabaXkn0anSF3xUKoLWX2Fxh2IDmslg%2BdkhGLWz45OOfCLYgUykwTWCpP0mLTzUbPE%2BkMNTZOqtkBrH22fn%2F%2Fx6vGgHJ90ONFA%2BnIoDKp%2Fo1KV7rULUTsQo%2BmZBJcg0kjMZWMo8hZx09CneGe3MvfFNb07IZy2cDU7qlSbujVlTd1Xi%2BhHoaukVf82gJI7L21KNGMi08eBmE%2BS8b4MxvfV89sW4XzZdvr3FhdslwuBa%2BVFNXWHeTqtU%2Fv9uWINgYvYzxN%2BsVFI2oYVzZD0Q8lErlDhZW4ERrbOc1sfg%3D%3D&Expires=1586609427 [following]\n",
            "--2020-04-10 00:50:28--  https://encode-public.s3.amazonaws.com/2016/12/11/5376e85f-a7ae-42d5-bc80-b478904eadf4/ENCFF724WMD.bam?response-content-disposition=attachment%3B%20filename%3DENCFF724WMD.bam&AWSAccessKeyId=ASIATGZNGCNX6CTJA57G&Signature=Pu%2B2WKGG8E%2BwIvOpSTrfmB4URDY%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCgbakfHzdOn26eGc%2BbP6pHZ6epdu8YaQOGmW3%2BvZ8eXAIhAKattsGFeQZj2Fl4BQZjwMVrRpiJpsyfLoy823kdK2bwKr0DCPr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMMjIwNzQ4NzE0ODYzIgxLUr5hvXcd83B5SOsqkQM%2FVrFf3%2BuH9qAlf5tsNqbr1GSNO%2BA0%2FJNx2yy2DkS16zNePxhzE3FzT%2FIiyqHURPlTQgTAQseDhjEeIQur71IXL%2BHI%2BI7pmQ6ucowOIGvC2rCivPi4Zky5vYRfJM%2BAkHqfjC6MU34y5cW9L3g11FJ%2Fr5nE7%2BEjB5AvqVl0tiBBwYBveZPI8ggih%2F6MG310L%2BhqB1wLrAT5x%2BQ9mtYQ3klBAd2f%2F0yrgB7KeLX5brCDf8GIJ0cc5R8dXfuaSODbDYOcbm%2F7EuJe2cwsnv9bAykFM3FQeyg29w6r6BnhdmwR9KfaBJRf1nWiN5cK5Lxd0IDTW7GWpfnftcVtYnF5t5kL3nrjfhQ%2FyoP0LYDF2uZJTPyk%2BxDt4mPKLUmK6ucYKy34bzvmR%2BGPJ8G2BJItXXPsKUQsIOjuc8651vUxXlPk%2Fa%2FpqPV6TYslnr9bManb7rZomJp7tVHQhQVGsfXWJ%2Fus0JGp%2FmecP8UaEOkdC8XtZJk6s23ebqbuRm9%2FIWZGcFcUK75TILIXB%2FcJ0Y2zDV0OhDCshL%2F0BTrqAbT7ZNH50Ku8ja15eJjdabaXkn0anSF3xUKoLWX2Fxh2IDmslg%2BdkhGLWz45OOfCLYgUykwTWCpP0mLTzUbPE%2BkMNTZOqtkBrH22fn%2F%2Fx6vGgHJ90ONFA%2BnIoDKp%2Fo1KV7rULUTsQo%2BmZBJcg0kjMZWMo8hZx09CneGe3MvfFNb07IZy2cDU7qlSbujVlTd1Xi%2BhHoaukVf82gJI7L21KNGMi08eBmE%2BS8b4MxvfV89sW4XzZdvr3FhdslwuBa%2BVFNXWHeTqtU%2Fv9uWINgYvYzxN%2BsVFI2oYVzZD0Q8lErlDhZW4ERrbOc1sfg%3D%3D&Expires=1586609427\n",
            "Resolving encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)... 52.218.243.107\n",
            "Connecting to encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)|52.218.243.107|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 799811309 (763M) [binary/octet-stream]\n",
            "Saving to: ‘rep1.bam’\n",
            "\n",
            "rep1.bam            100%[===================>] 762.76M  19.4MB/s    in 41s     \n",
            "\n",
            "2020-04-10 00:51:10 (18.4 MB/s) - ‘rep1.bam’ saved [799811309/799811309]\n",
            "\n",
            "--2020-04-10 00:51:11--  https://www.encodeproject.org/files/ENCFF482TVZ/@@download/ENCFF482TVZ.bam\n",
            "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
            "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://encode-public.s3.amazonaws.com/2016/12/10/175fdff1-1764-46e1-9345-b60bccb232e0/ENCFF482TVZ.bam?response-content-disposition=attachment%3B%20filename%3DENCFF482TVZ.bam&AWSAccessKeyId=ASIATGZNGCNXRK6CN5NX&Signature=bV3OYmwKkNMrjcvI%2B3ajVwTQxps%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDdIqixY4pV6LjAEZ49x9PtRxAt0AFkLQOaSKstUGGPVwIgUqDtqyMLupU3isOk8ptVaho8UBTbkipNkVP3CekcVogqvQMI%2Bf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgwyMjA3NDg3MTQ4NjMiDO8VPPyZLQrczxoFhyqRAwsKqX5fXx2Zuz2sFQWFGjJs%2BpHonPggk5MfW8GUWHVBEYebKm3hNTK%2F1YV7ICqrx%2Btws%2BYt50ztAFS1%2FFU5kfzAA73vpsUkhRnE6DR72Ny9tmpBOgGzNb8y19GHxgbvRSrFfRskRaSui%2BRw9384viLw%2F3IuHlLz%2F39RikzKVpXh2gXUvhXaMgr6z9y0uUsIfVr6cxUlYi2JDVQdv7lD%2FsvbX2Bqv3Gs2%2BgPej1spgpHBqNi8rdX9OLql79F6G90VFukXbBKlTAiM8Bj1dDz6S%2F0zR6yXmjNBiNrpPMNKKZkSQHex5S9uzWd9BNPGrNhzDRrzRHNqjTfWGYTpYvp514j8YLPZBioaMsvkIzktPhT51VsnNzuJjsWtY8jXhWpPmBsqCmKz2Vv8CACetBHfRcTpFiDHcmR25%2F4wo0jgtrm9A0GVsly1KqTsy6K8Llk0nap2nZtEFfn7E3QvJRCix39gzjGXePQCFVtAtDFjgccEgDOfU59VfeLLlurrgJzkY5xCxDSawcY2x5a5WZICOZ6MJzovvQFOusBu3hq5HXA9W96mbh1BFKuE8NnskMS6npZlUrbs4qGpsR6Dir1b%2BL4dksRRrEXeN%2BYiaxVuVGpSoosXyhg6OE2CE36JyqQcIPih625DwSbX4diXzgEivZ%2BwTed12Ydmp3YWttUxzsAiOApeZzhhOl97e8D6bp7ingyfOlAY2yZik%2Bd8IKOl9lNaj3tyEFygHXK8vh6t1I8e2mCuuCxgmkZvk3SV%2Flc%2FziCstTOt80oG52jLdgOa7SJu7sHLgQ%2BFBpjPq02syhHkLPaXWyOZOzpoJSC%2FLhAskYoAXR4D0vPcSyXh%2FlTcdHviy9%2B9g%3D%3D&Expires=1586609471 [following]\n",
            "--2020-04-10 00:51:11--  https://encode-public.s3.amazonaws.com/2016/12/10/175fdff1-1764-46e1-9345-b60bccb232e0/ENCFF482TVZ.bam?response-content-disposition=attachment%3B%20filename%3DENCFF482TVZ.bam&AWSAccessKeyId=ASIATGZNGCNXRK6CN5NX&Signature=bV3OYmwKkNMrjcvI%2B3ajVwTQxps%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDdIqixY4pV6LjAEZ49x9PtRxAt0AFkLQOaSKstUGGPVwIgUqDtqyMLupU3isOk8ptVaho8UBTbkipNkVP3CekcVogqvQMI%2Bf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgwyMjA3NDg3MTQ4NjMiDO8VPPyZLQrczxoFhyqRAwsKqX5fXx2Zuz2sFQWFGjJs%2BpHonPggk5MfW8GUWHVBEYebKm3hNTK%2F1YV7ICqrx%2Btws%2BYt50ztAFS1%2FFU5kfzAA73vpsUkhRnE6DR72Ny9tmpBOgGzNb8y19GHxgbvRSrFfRskRaSui%2BRw9384viLw%2F3IuHlLz%2F39RikzKVpXh2gXUvhXaMgr6z9y0uUsIfVr6cxUlYi2JDVQdv7lD%2FsvbX2Bqv3Gs2%2BgPej1spgpHBqNi8rdX9OLql79F6G90VFukXbBKlTAiM8Bj1dDz6S%2F0zR6yXmjNBiNrpPMNKKZkSQHex5S9uzWd9BNPGrNhzDRrzRHNqjTfWGYTpYvp514j8YLPZBioaMsvkIzktPhT51VsnNzuJjsWtY8jXhWpPmBsqCmKz2Vv8CACetBHfRcTpFiDHcmR25%2F4wo0jgtrm9A0GVsly1KqTsy6K8Llk0nap2nZtEFfn7E3QvJRCix39gzjGXePQCFVtAtDFjgccEgDOfU59VfeLLlurrgJzkY5xCxDSawcY2x5a5WZICOZ6MJzovvQFOusBu3hq5HXA9W96mbh1BFKuE8NnskMS6npZlUrbs4qGpsR6Dir1b%2BL4dksRRrEXeN%2BYiaxVuVGpSoosXyhg6OE2CE36JyqQcIPih625DwSbX4diXzgEivZ%2BwTed12Ydmp3YWttUxzsAiOApeZzhhOl97e8D6bp7ingyfOlAY2yZik%2Bd8IKOl9lNaj3tyEFygHXK8vh6t1I8e2mCuuCxgmkZvk3SV%2Flc%2FziCstTOt80oG52jLdgOa7SJu7sHLgQ%2BFBpjPq02syhHkLPaXWyOZOzpoJSC%2FLhAskYoAXR4D0vPcSyXh%2FlTcdHviy9%2B9g%3D%3D&Expires=1586609471\n",
            "Resolving encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)... 52.218.220.139\n",
            "Connecting to encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)|52.218.220.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 641977911 (612M) [binary/octet-stream]\n",
            "Saving to: ‘rep2.bam’\n",
            "\n",
            "rep2.bam            100%[===================>] 612.24M  19.6MB/s    in 33s     \n",
            "\n",
            "2020-04-10 00:51:45 (18.7 MB/s) - ‘rep2.bam’ saved [641977911/641977911]\n",
            "\n",
            "--2020-04-10 00:51:46--  https://www.encodeproject.org/files/ENCFF857FLV/@@download/ENCFF857FLV.bam\n",
            "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
            "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://encode-public.s3.amazonaws.com/2016/10/26/5131dba7-e33a-4a12-9ac2-56371a5400f7/ENCFF857FLV.bam?response-content-disposition=attachment%3B%20filename%3DENCFF857FLV.bam&AWSAccessKeyId=ASIATGZNGCNXRK6CN5NX&Signature=CpbFD%2BAQyX%2BjjOh9cJFejIcx3m0%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDdIqixY4pV6LjAEZ49x9PtRxAt0AFkLQOaSKstUGGPVwIgUqDtqyMLupU3isOk8ptVaho8UBTbkipNkVP3CekcVogqvQMI%2Bf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgwyMjA3NDg3MTQ4NjMiDO8VPPyZLQrczxoFhyqRAwsKqX5fXx2Zuz2sFQWFGjJs%2BpHonPggk5MfW8GUWHVBEYebKm3hNTK%2F1YV7ICqrx%2Btws%2BYt50ztAFS1%2FFU5kfzAA73vpsUkhRnE6DR72Ny9tmpBOgGzNb8y19GHxgbvRSrFfRskRaSui%2BRw9384viLw%2F3IuHlLz%2F39RikzKVpXh2gXUvhXaMgr6z9y0uUsIfVr6cxUlYi2JDVQdv7lD%2FsvbX2Bqv3Gs2%2BgPej1spgpHBqNi8rdX9OLql79F6G90VFukXbBKlTAiM8Bj1dDz6S%2F0zR6yXmjNBiNrpPMNKKZkSQHex5S9uzWd9BNPGrNhzDRrzRHNqjTfWGYTpYvp514j8YLPZBioaMsvkIzktPhT51VsnNzuJjsWtY8jXhWpPmBsqCmKz2Vv8CACetBHfRcTpFiDHcmR25%2F4wo0jgtrm9A0GVsly1KqTsy6K8Llk0nap2nZtEFfn7E3QvJRCix39gzjGXePQCFVtAtDFjgccEgDOfU59VfeLLlurrgJzkY5xCxDSawcY2x5a5WZICOZ6MJzovvQFOusBu3hq5HXA9W96mbh1BFKuE8NnskMS6npZlUrbs4qGpsR6Dir1b%2BL4dksRRrEXeN%2BYiaxVuVGpSoosXyhg6OE2CE36JyqQcIPih625DwSbX4diXzgEivZ%2BwTed12Ydmp3YWttUxzsAiOApeZzhhOl97e8D6bp7ingyfOlAY2yZik%2Bd8IKOl9lNaj3tyEFygHXK8vh6t1I8e2mCuuCxgmkZvk3SV%2Flc%2FziCstTOt80oG52jLdgOa7SJu7sHLgQ%2BFBpjPq02syhHkLPaXWyOZOzpoJSC%2FLhAskYoAXR4D0vPcSyXh%2FlTcdHviy9%2B9g%3D%3D&Expires=1586609507 [following]\n",
            "--2020-04-10 00:51:47--  https://encode-public.s3.amazonaws.com/2016/10/26/5131dba7-e33a-4a12-9ac2-56371a5400f7/ENCFF857FLV.bam?response-content-disposition=attachment%3B%20filename%3DENCFF857FLV.bam&AWSAccessKeyId=ASIATGZNGCNXRK6CN5NX&Signature=CpbFD%2BAQyX%2BjjOh9cJFejIcx3m0%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIQDdIqixY4pV6LjAEZ49x9PtRxAt0AFkLQOaSKstUGGPVwIgUqDtqyMLupU3isOk8ptVaho8UBTbkipNkVP3CekcVogqvQMI%2Bf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgwyMjA3NDg3MTQ4NjMiDO8VPPyZLQrczxoFhyqRAwsKqX5fXx2Zuz2sFQWFGjJs%2BpHonPggk5MfW8GUWHVBEYebKm3hNTK%2F1YV7ICqrx%2Btws%2BYt50ztAFS1%2FFU5kfzAA73vpsUkhRnE6DR72Ny9tmpBOgGzNb8y19GHxgbvRSrFfRskRaSui%2BRw9384viLw%2F3IuHlLz%2F39RikzKVpXh2gXUvhXaMgr6z9y0uUsIfVr6cxUlYi2JDVQdv7lD%2FsvbX2Bqv3Gs2%2BgPej1spgpHBqNi8rdX9OLql79F6G90VFukXbBKlTAiM8Bj1dDz6S%2F0zR6yXmjNBiNrpPMNKKZkSQHex5S9uzWd9BNPGrNhzDRrzRHNqjTfWGYTpYvp514j8YLPZBioaMsvkIzktPhT51VsnNzuJjsWtY8jXhWpPmBsqCmKz2Vv8CACetBHfRcTpFiDHcmR25%2F4wo0jgtrm9A0GVsly1KqTsy6K8Llk0nap2nZtEFfn7E3QvJRCix39gzjGXePQCFVtAtDFjgccEgDOfU59VfeLLlurrgJzkY5xCxDSawcY2x5a5WZICOZ6MJzovvQFOusBu3hq5HXA9W96mbh1BFKuE8NnskMS6npZlUrbs4qGpsR6Dir1b%2BL4dksRRrEXeN%2BYiaxVuVGpSoosXyhg6OE2CE36JyqQcIPih625DwSbX4diXzgEivZ%2BwTed12Ydmp3YWttUxzsAiOApeZzhhOl97e8D6bp7ingyfOlAY2yZik%2Bd8IKOl9lNaj3tyEFygHXK8vh6t1I8e2mCuuCxgmkZvk3SV%2Flc%2FziCstTOt80oG52jLdgOa7SJu7sHLgQ%2BFBpjPq02syhHkLPaXWyOZOzpoJSC%2FLhAskYoAXR4D0vPcSyXh%2FlTcdHviy9%2B9g%3D%3D&Expires=1586609507\n",
            "Resolving encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)... 52.218.232.66\n",
            "Connecting to encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)|52.218.232.66|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 730564705 (697M) [binary/octet-stream]\n",
            "Saving to: ‘control.bam’\n",
            "\n",
            "control.bam         100%[===================>] 696.72M  19.3MB/s    in 38s     \n",
            "\n",
            "2020-04-10 00:52:25 (18.6 MB/s) - ‘control.bam’ saved [730564705/730564705]\n",
            "\n",
            "--2020-04-10 00:52:27--  https://www.encodeproject.org/files/ENCFF744AGB/@@download/ENCFF744AGB.bed.gz\n",
            "Resolving www.encodeproject.org (www.encodeproject.org)... 34.211.244.144\n",
            "Connecting to www.encodeproject.org (www.encodeproject.org)|34.211.244.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: https://encode-public.s3.amazonaws.com/2016/12/16/1525a0f6-ed1a-4103-8c05-42c2a3a5beb7/ENCFF744AGB.bed.gz?response-content-disposition=attachment%3B%20filename%3DENCFF744AGB.bed.gz&AWSAccessKeyId=ASIATGZNGCNX6CTJA57G&Signature=NFS9jYAdnh7mobEZuwqGR2Jc0mc%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCgbakfHzdOn26eGc%2BbP6pHZ6epdu8YaQOGmW3%2BvZ8eXAIhAKattsGFeQZj2Fl4BQZjwMVrRpiJpsyfLoy823kdK2bwKr0DCPr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMMjIwNzQ4NzE0ODYzIgxLUr5hvXcd83B5SOsqkQM%2FVrFf3%2BuH9qAlf5tsNqbr1GSNO%2BA0%2FJNx2yy2DkS16zNePxhzE3FzT%2FIiyqHURPlTQgTAQseDhjEeIQur71IXL%2BHI%2BI7pmQ6ucowOIGvC2rCivPi4Zky5vYRfJM%2BAkHqfjC6MU34y5cW9L3g11FJ%2Fr5nE7%2BEjB5AvqVl0tiBBwYBveZPI8ggih%2F6MG310L%2BhqB1wLrAT5x%2BQ9mtYQ3klBAd2f%2F0yrgB7KeLX5brCDf8GIJ0cc5R8dXfuaSODbDYOcbm%2F7EuJe2cwsnv9bAykFM3FQeyg29w6r6BnhdmwR9KfaBJRf1nWiN5cK5Lxd0IDTW7GWpfnftcVtYnF5t5kL3nrjfhQ%2FyoP0LYDF2uZJTPyk%2BxDt4mPKLUmK6ucYKy34bzvmR%2BGPJ8G2BJItXXPsKUQsIOjuc8651vUxXlPk%2Fa%2FpqPV6TYslnr9bManb7rZomJp7tVHQhQVGsfXWJ%2Fus0JGp%2FmecP8UaEOkdC8XtZJk6s23ebqbuRm9%2FIWZGcFcUK75TILIXB%2FcJ0Y2zDV0OhDCshL%2F0BTrqAbT7ZNH50Ku8ja15eJjdabaXkn0anSF3xUKoLWX2Fxh2IDmslg%2BdkhGLWz45OOfCLYgUykwTWCpP0mLTzUbPE%2BkMNTZOqtkBrH22fn%2F%2Fx6vGgHJ90ONFA%2BnIoDKp%2Fo1KV7rULUTsQo%2BmZBJcg0kjMZWMo8hZx09CneGe3MvfFNb07IZy2cDU7qlSbujVlTd1Xi%2BhHoaukVf82gJI7L21KNGMi08eBmE%2BS8b4MxvfV89sW4XzZdvr3FhdslwuBa%2BVFNXWHeTqtU%2Fv9uWINgYvYzxN%2BsVFI2oYVzZD0Q8lErlDhZW4ERrbOc1sfg%3D%3D&Expires=1586609548 [following]\n",
            "--2020-04-10 00:52:28--  https://encode-public.s3.amazonaws.com/2016/12/16/1525a0f6-ed1a-4103-8c05-42c2a3a5beb7/ENCFF744AGB.bed.gz?response-content-disposition=attachment%3B%20filename%3DENCFF744AGB.bed.gz&AWSAccessKeyId=ASIATGZNGCNX6CTJA57G&Signature=NFS9jYAdnh7mobEZuwqGR2Jc0mc%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEPH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIMEYCIQCgbakfHzdOn26eGc%2BbP6pHZ6epdu8YaQOGmW3%2BvZ8eXAIhAKattsGFeQZj2Fl4BQZjwMVrRpiJpsyfLoy823kdK2bwKr0DCPr%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMMjIwNzQ4NzE0ODYzIgxLUr5hvXcd83B5SOsqkQM%2FVrFf3%2BuH9qAlf5tsNqbr1GSNO%2BA0%2FJNx2yy2DkS16zNePxhzE3FzT%2FIiyqHURPlTQgTAQseDhjEeIQur71IXL%2BHI%2BI7pmQ6ucowOIGvC2rCivPi4Zky5vYRfJM%2BAkHqfjC6MU34y5cW9L3g11FJ%2Fr5nE7%2BEjB5AvqVl0tiBBwYBveZPI8ggih%2F6MG310L%2BhqB1wLrAT5x%2BQ9mtYQ3klBAd2f%2F0yrgB7KeLX5brCDf8GIJ0cc5R8dXfuaSODbDYOcbm%2F7EuJe2cwsnv9bAykFM3FQeyg29w6r6BnhdmwR9KfaBJRf1nWiN5cK5Lxd0IDTW7GWpfnftcVtYnF5t5kL3nrjfhQ%2FyoP0LYDF2uZJTPyk%2BxDt4mPKLUmK6ucYKy34bzvmR%2BGPJ8G2BJItXXPsKUQsIOjuc8651vUxXlPk%2Fa%2FpqPV6TYslnr9bManb7rZomJp7tVHQhQVGsfXWJ%2Fus0JGp%2FmecP8UaEOkdC8XtZJk6s23ebqbuRm9%2FIWZGcFcUK75TILIXB%2FcJ0Y2zDV0OhDCshL%2F0BTrqAbT7ZNH50Ku8ja15eJjdabaXkn0anSF3xUKoLWX2Fxh2IDmslg%2BdkhGLWz45OOfCLYgUykwTWCpP0mLTzUbPE%2BkMNTZOqtkBrH22fn%2F%2Fx6vGgHJ90ONFA%2BnIoDKp%2Fo1KV7rULUTsQo%2BmZBJcg0kjMZWMo8hZx09CneGe3MvfFNb07IZy2cDU7qlSbujVlTd1Xi%2BhHoaukVf82gJI7L21KNGMi08eBmE%2BS8b4MxvfV89sW4XzZdvr3FhdslwuBa%2BVFNXWHeTqtU%2Fv9uWINgYvYzxN%2BsVFI2oYVzZD0Q8lErlDhZW4ERrbOc1sfg%3D%3D&Expires=1586609548\n",
            "Resolving encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)... 52.218.246.219\n",
            "Connecting to encode-public.s3.amazonaws.com (encode-public.s3.amazonaws.com)|52.218.246.219|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 924057 (902K) [binary/octet-stream]\n",
            "Saving to: ‘peaks.bed.gz’\n",
            "\n",
            "peaks.bed.gz        100%[===================>] 902.40K  1.16MB/s    in 0.8s    \n",
            "\n",
            "2020-04-10 00:52:29 (1.16 MB/s) - ‘peaks.bed.gz’ saved [924057/924057]\n",
            "\n",
            "--2020-04-10 00:52:31--  http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.2bit\n",
            "Resolving hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 835393456 (797M) [text/plain]\n",
            "Saving to: ‘hg38.2bit’\n",
            "\n",
            "hg38.2bit           100%[===================>] 796.69M  19.5MB/s    in 59s     \n",
            "\n",
            "2020-04-10 00:53:30 (13.6 MB/s) - ‘hg38.2bit’ saved [835393456/835393456]\n",
            "\n",
            "--2020-04-10 00:53:31--  http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5924440 (5.6M) [text/plain]\n",
            "Saving to: ‘twoBitToFa’\n",
            "\n",
            "twoBitToFa          100%[===================>]   5.65M   926KB/s    in 7.5s    \n",
            "\n",
            "2020-04-10 00:53:39 (768 KB/s) - ‘twoBitToFa’ saved [5924440/5924440]\n",
            "\n",
            "--2020-04-10 00:54:38--  https://raw.githubusercontent.com/ENCODE-DCC/encValData/master/GRCh38/GRCh38_EBV.chrom.sizes\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11686 (11K) [text/plain]\n",
            "Saving to: ‘hg38.chrom.sizes’\n",
            "\n",
            "hg38.chrom.sizes    100%[===================>]  11.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-10 00:54:38 (151 MB/s) - ‘hg38.chrom.sizes’ saved [11686/11686]\n",
            "\n",
            "--2020-04-10 00:54:39--  http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/bedGraphToBigWig\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5207552 (5.0M) [text/plain]\n",
            "Saving to: ‘bedGraphToBigWig’\n",
            "\n",
            "bedGraphToBigWig    100%[===================>]   4.97M   831KB/s    in 7.0s    \n",
            "\n",
            "2020-04-10 00:54:46 (725 KB/s) - ‘bedGraphToBigWig’ saved [5207552/5207552]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhv6AnRSw2pE",
        "colab_type": "code",
        "outputId": "52088008-0b40-4b68-da0c-02215d7d1f34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "!apt-get install bedtools\n",
        "!pip install pyfaidx\n",
        "!pip install pyBigWig"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  bedtools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 25 not upgraded.\n",
            "Need to get 577 kB of archives.\n",
            "After this operation, 2,040 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 bedtools amd64 2.26.0+dfsg-5 [577 kB]\n",
            "Fetched 577 kB in 0s (5,321 kB/s)\n",
            "Selecting previously unselected package bedtools.\n",
            "(Reading database ... 144568 files and directories currently installed.)\n",
            "Preparing to unpack .../bedtools_2.26.0+dfsg-5_amd64.deb ...\n",
            "Unpacking bedtools (2.26.0+dfsg-5) ...\n",
            "Setting up bedtools (2.26.0+dfsg-5) ...\n",
            "Collecting pyfaidx\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/eb/bca4c916d2cde775b5127cef22f276142b01e89fc31fecd832ed996dc97e/pyfaidx-0.5.8.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyfaidx) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx) (46.1.3)\n",
            "Building wheels for collected packages: pyfaidx\n",
            "  Building wheel for pyfaidx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfaidx: filename=pyfaidx-0.5.8-cp36-none-any.whl size=25051 sha256=af356c4cfd3a0e87c8c671d98b0b23f7cc68fa6b98d58edf822aa77c2408cb8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/ea/ee/59d4649b0fb82a0690bdeae834bc85891b306126bcc067e29f\n",
            "Successfully built pyfaidx\n",
            "Installing collected packages: pyfaidx\n",
            "Successfully installed pyfaidx-0.5.8\n",
            "Collecting pyBigWig\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/e2/cf945d541a10bb9c675f986d5bf0b0268544721054d17cc6260cfcfb3685/pyBigWig-0.3.17.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyBigWig\n",
            "  Building wheel for pyBigWig (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyBigWig: filename=pyBigWig-0.3.17-cp36-cp36m-linux_x86_64.whl size=178046 sha256=202077acba57d44e82984ca004511481634d4e6c40572834c538bee991f38da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/27/2d/ac3e2e2d17894877fd3c4595ebd6fbd25ad805bfeab333f19b\n",
            "Successfully built pyBigWig\n",
            "Installing collected packages: pyBigWig\n",
            "Successfully installed pyBigWig-0.3.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSEzVgSOJJrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get 1kb around summits\n",
        "![[ -f 1k_around_summits.bed.gz ]] || zcat peaks.bed.gz | perl -lane 'print $F[0].\"\\t\".(($F[1]+$F[9])).\"\\t\".(($F[1]+$F[9]))' | bedtools slop -g hg38.chrom.sizes -b 500 | perl -lane 'if ($F[2]-$F[1]==1000) {print $F[0].\"\\t\".$F[1].\"\\t\".$F[2].\"\\t1\"}' | sortBed | gzip -c > 1k_around_summits.bed.gz\n",
        "#split into train, valid, test sets\n",
        "![[ -f test_1k_around_summits.bed.gz ]] || zcat 1k_around_summits.bed.gz | egrep -w 'chr1|chr8|chr21' | gzip -c > test_1k_around_summits.bed.gz\n",
        "![[ -f valid_1k_around_summits.bed.gz ]] || zcat 1k_around_summits.bed.gz | egrep -w 'chr22' | gzip -c > valid_1k_around_summits.bed.gz\n",
        "![[ -f train_1k_around_summits.bed.gz ]] || zcat 1k_around_summits.bed.gz | egrep -w -v 'chr1|chr8|chr21|chr22' | gzip -c > train_1k_around_summits.bed.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IJbyEGa5GOY",
        "colab_type": "code",
        "outputId": "1a60ecfa-484e-4524-e102-39a5956f1390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content\n",
        "![[ -f samtools-1.9.tar.bz2 ]] || wget https://github.com/samtools/samtools/releases/download/1.9/samtools-1.9.tar.bz2\n",
        "!tar -xjf samtools-1.9.tar.bz2\n",
        "%cd samtools-1.9\n",
        "!./configure\n",
        "!make\n",
        "!make install\n",
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "--2020-04-10 01:22:54--  https://github.com/samtools/samtools/releases/download/1.9/samtools-1.9.tar.bz2\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/3666841/fe586164-8a73-11e8-84ad-bb90bbd3b7c0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200410%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200410T012255Z&X-Amz-Expires=300&X-Amz-Signature=e90fbdb104a8cec002e99cf909ce170a967640d783b2d983ed032b122671c00e&X-Amz-SignedHeaders=host&actor_id=0&repo_id=3666841&response-content-disposition=attachment%3B%20filename%3Dsamtools-1.9.tar.bz2&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-04-10 01:22:55--  https://github-production-release-asset-2e65be.s3.amazonaws.com/3666841/fe586164-8a73-11e8-84ad-bb90bbd3b7c0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200410%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200410T012255Z&X-Amz-Expires=300&X-Amz-Signature=e90fbdb104a8cec002e99cf909ce170a967640d783b2d983ed032b122671c00e&X-Amz-SignedHeaders=host&actor_id=0&repo_id=3666841&response-content-disposition=attachment%3B%20filename%3Dsamtools-1.9.tar.bz2&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.106.27\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.106.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4440405 (4.2M) [application/octet-stream]\n",
            "Saving to: ‘samtools-1.9.tar.bz2’\n",
            "\n",
            "samtools-1.9.tar.bz 100%[===================>]   4.23M  6.26MB/s    in 0.7s    \n",
            "\n",
            "2020-04-10 01:22:56 (6.26 MB/s) - ‘samtools-1.9.tar.bz2’ saved [4440405/4440405]\n",
            "\n",
            "/content/samtools-1.9\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for special C compiler options needed for large files... no\n",
            "checking for _FILE_OFFSET_BITS value needed for large files... no\n",
            "checking location of HTSlib source tree... htslib-1.9\n",
            "checking for NcursesW wide-character library... no\n",
            "checking for Ncurses library... yes\n",
            "checking for working ncurses/curses.h... no\n",
            "checking for working ncurses.h... yes\n",
            "checking for zlib.h... yes\n",
            "checking for inflate in -lz... yes\n",
            "checking for library containing regcomp... none required\n",
            "configure: creating ./config.status\n",
            "config.status: creating config.mk\n",
            "config.status: creating config.h\n",
            "=== configuring in htslib-1.9 (/content/samtools-1.9/htslib-1.9)\n",
            "configure: running /bin/bash ./configure --disable-option-checking '--prefix=/usr/local'  --cache-file=/dev/null --srcdir=.\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for ranlib... ranlib\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for C compiler warning flags... -Wall\n",
            "checking for special C compiler options needed for large files... no\n",
            "checking for _FILE_OFFSET_BITS value needed for large files... no\n",
            "checking for _LARGEFILE_SOURCE value needed for large files... no\n",
            "checking shared library type for unknown-Linux... plain .so\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for egrep... /bin/grep -E\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for gmtime_r... yes\n",
            "checking for fsync... yes\n",
            "checking for drand48... yes\n",
            "checking whether fdatasync is declared... yes\n",
            "checking for fdatasync... yes\n",
            "checking for library containing log... -lm\n",
            "checking for zlib.h... yes\n",
            "checking for inflate in -lz... yes\n",
            "checking for library containing recv... none required\n",
            "checking for bzlib.h... yes\n",
            "checking for BZ2_bzBuffToBuffCompress in -lbz2... yes\n",
            "checking for lzma.h... yes\n",
            "checking for lzma_easy_buffer_encode in -llzma... yes\n",
            "checking for libdeflate.h... no\n",
            "checking for libdeflate_deflate_compress in -ldeflate... no\n",
            "checking for curl_easy_pause in -lcurl... yes\n",
            "checking for CCHmac... no\n",
            "checking for library containing HMAC... -lcrypto\n",
            "checking whether PTHREAD_MUTEX_RECURSIVE is declared... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating config.mk\n",
            "config.status: creating htslib.pc.tmp\n",
            "config.status: creating config.h\n",
            "config.mk:45: htslib-1.9/htslib_static.mk: No such file or directory\n",
            "cd htslib-1.9 && make htslib_static.mk\n",
            "make[1]: Entering directory '/content/samtools-1.9/htslib-1.9'\n",
            "sed -n '/^static_libs=/s/[^=]*=/HTSLIB_static_LIBS = /p;/^static_ldflags=/s/[^=]*=/HTSLIB_static_LDFLAGS = /p' htslib.pc.tmp > htslib_static.mk\n",
            "make[1]: Leaving directory '/content/samtools-1.9/htslib-1.9'\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_index.o bam_index.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_plcmd.o bam_plcmd.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o sam_view.o sam_view.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_cat.o bam_cat.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_md.o bam_md.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_reheader.o bam_reheader.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_sort.o bam_sort.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bedidx.o bedidx.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_rmdup.o bam_rmdup.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_rmdupse.o bam_rmdupse.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_mate.o bam_mate.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_stat.o bam_stat.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_color.o bam_color.c\n",
            "echo '#define SAMTOOLS_VERSION \"1.9\"' > version.h\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bamtk.o bamtk.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam2bcf.o bam2bcf.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam2bcf_indel.o bam2bcf_indel.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o sample.o sample.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o cut_target.o cut_target.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o phase.o phase.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam2depth.o bam2depth.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o padding.o padding.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bedcov.o bedcov.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bamshuf.o bamshuf.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o faidx.o faidx.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o dict.o dict.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o stats.o stats.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o stats_isize.o stats_isize.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_flags.o bam_flags.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_split.o bam_split.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_tview.o bam_tview.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_tview_curses.o bam_tview_curses.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_tview_html.o bam_tview_html.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_lpileup.o bam_lpileup.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_quickcheck.o bam_quickcheck.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_addrprg.o bam_addrprg.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_markdup.o bam_markdup.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o tmp_file.o tmp_file.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o lz4/lz4.o lz4/lz4.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_aux.o bam_aux.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam.o bam.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_import.o bam_import.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o sam.o sam.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o sam_header.o sam_header.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o bam_plbuf.o bam_plbuf.c\n",
            "ar -csru libbam.a bam_aux.o bam.o bam_import.o sam.o sam_header.o bam_plbuf.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o sam_opts.o sam_opts.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o sam_utils.o sam_utils.c\n",
            "ar -rcs libst.a sam_opts.o sam_utils.o\n",
            "cd htslib-1.9 && make lib-static\n",
            "make[1]: Entering directory '/content/samtools-1.9/htslib-1.9'\n",
            "gcc -Wall -g -O2 -I.  -c -o kfunc.o kfunc.c\n",
            "gcc -Wall -g -O2 -I.  -c -o knetfile.o knetfile.c\n",
            "gcc -Wall -g -O2 -I.  -c -o kstring.o kstring.c\n",
            "gcc -Wall -g -O2 -I.  -c -o bcf_sr_sort.o bcf_sr_sort.c\n",
            "gcc -Wall -g -O2 -I.  -c -o bgzf.o bgzf.c\n",
            "gcc -Wall -g -O2 -I.  -c -o errmod.o errmod.c\n",
            "gcc -Wall -g -O2 -I.  -c -o faidx.o faidx.c\n",
            "gcc -Wall -g -O2 -I.  -c -o hfile.o hfile.c\n",
            "gcc -Wall -g -O2 -I.  -c -o hfile_net.o hfile_net.c\n",
            "echo '#define HTS_VERSION \"1.9\"' > version.h\n",
            "gcc -Wall -g -O2 -I.  -c -o hts.o hts.c\n",
            "gcc -Wall -g -O2 -I.  -c -o hts_os.o hts_os.c\n",
            "gcc -Wall -g -O2 -I.  -c -o md5.o md5.c\n",
            "gcc -Wall -g -O2 -I.  -c -o multipart.o multipart.c\n",
            "gcc -Wall -g -O2 -I.  -c -o probaln.o probaln.c\n",
            "gcc -Wall -g -O2 -I.  -c -o realn.o realn.c\n",
            "gcc -Wall -g -O2 -I.  -c -o regidx.o regidx.c\n",
            "gcc -Wall -g -O2 -I.  -c -o sam.o sam.c\n",
            "gcc -Wall -g -O2 -I.  -c -o synced_bcf_reader.o synced_bcf_reader.c\n",
            "gcc -Wall -g -O2 -I.  -c -o vcf_sweep.o vcf_sweep.c\n",
            "gcc -Wall -g -O2 -I.  -c -o tbx.o tbx.c\n",
            "gcc -Wall -g -O2 -I.  -c -o textutils.o textutils.c\n",
            "gcc -Wall -g -O2 -I.  -c -o thread_pool.o thread_pool.c\n",
            "gcc -Wall -g -O2 -I.  -c -o vcf.o vcf.c\n",
            "gcc -Wall -g -O2 -I.  -c -o vcfutils.o vcfutils.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_codecs.o cram/cram_codecs.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_decode.o cram/cram_decode.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_encode.o cram/cram_encode.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_external.o cram/cram_external.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_index.o cram/cram_index.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_io.o cram/cram_io.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_samtools.o cram/cram_samtools.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/cram_stats.o cram/cram_stats.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/files.o cram/files.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/mFILE.o cram/mFILE.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/open_trace_file.o cram/open_trace_file.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/pooled_alloc.o cram/pooled_alloc.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/rANS_static.o cram/rANS_static.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/sam_header.o cram/sam_header.c\n",
            "gcc -Wall -g -O2 -I.  -c -o cram/string_alloc.o cram/string_alloc.c\n",
            "gcc -Wall -g -O2 -I.  -c -o hfile_libcurl.o hfile_libcurl.c\n",
            "gcc -Wall -g -O2 -I.  -c -o hfile_gcs.o hfile_gcs.c\n",
            "gcc -Wall -g -O2 -I.  -c -o hfile_s3.o hfile_s3.c\n",
            "ar -rc libhts.a kfunc.o knetfile.o kstring.o bcf_sr_sort.o bgzf.o errmod.o faidx.o hfile.o hfile_net.o hts.o hts_os.o md5.o multipart.o probaln.o realn.o regidx.o sam.o synced_bcf_reader.o vcf_sweep.o tbx.o textutils.o thread_pool.o vcf.o vcfutils.o cram/cram_codecs.o cram/cram_decode.o cram/cram_encode.o cram/cram_external.o cram/cram_index.o cram/cram_io.o cram/cram_samtools.o cram/cram_stats.o cram/files.o cram/mFILE.o cram/open_trace_file.o cram/pooled_alloc.o cram/rANS_static.o cram/sam_header.o cram/string_alloc.o  hfile_libcurl.o hfile_gcs.o hfile_s3.o\n",
            "ranlib libhts.a\n",
            "make[1]: Leaving directory '/content/samtools-1.9/htslib-1.9'\n",
            "gcc  -L./lz4  -o samtools bam_index.o bam_plcmd.o sam_view.o bam_cat.o bam_md.o bam_reheader.o bam_sort.o bedidx.o bam_rmdup.o bam_rmdupse.o bam_mate.o bam_stat.o bam_color.o bamtk.o bam2bcf.o bam2bcf_indel.o sample.o cut_target.o phase.o bam2depth.o padding.o bedcov.o bamshuf.o faidx.o dict.o stats.o stats_isize.o bam_flags.o bam_split.o bam_tview.o bam_tview_curses.o bam_tview_html.o bam_lpileup.o bam_quickcheck.o bam_addrprg.o bam_markdup.o tmp_file.o ./lz4/lz4.o libbam.a libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lncurses -lm -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o misc/ace2sam.o misc/ace2sam.c\n",
            "gcc  -o misc/ace2sam misc/ace2sam.o -lz \n",
            "gcc -g -O2 -DMAQ_LONGREADS -I. -Ihtslib-1.9 -I./lz4  -c -o misc/maq2sam-long.o misc/maq2sam.c\n",
            "gcc  -o misc/maq2sam-long misc/maq2sam-long.o -lz \n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o misc/maq2sam-short.o misc/maq2sam.c\n",
            "gcc  -o misc/maq2sam-short misc/maq2sam-short.o -lz \n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o misc/md5fa.o misc/md5fa.c\n",
            "gcc  -L./lz4  -o misc/md5fa misc/md5fa.o htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz \n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o misc/md5sum-lite.o misc/md5sum-lite.c\n",
            "gcc  -L./lz4  -o misc/md5sum-lite misc/md5sum-lite.o htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz \n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o misc/wgsim.o misc/wgsim.c\n",
            "gcc  -L./lz4  -o misc/wgsim misc/wgsim.o -lm htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz \n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/merge/test_bam_translate.o test/merge/test_bam_translate.c\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/test.o test/test.c\n",
            "gcc  -L./lz4  -o test/merge/test_bam_translate test/merge/test_bam_translate.o test/test.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/merge/test_rtrans_build.o test/merge/test_rtrans_build.c\n",
            "gcc  -L./lz4  -o test/merge/test_rtrans_build test/merge/test_rtrans_build.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/merge/test_trans_tbl_init.o test/merge/test_trans_tbl_init.c\n",
            "gcc  -L./lz4  -o test/merge/test_trans_tbl_init test/merge/test_trans_tbl_init.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/split/test_count_rg.o test/split/test_count_rg.c\n",
            "gcc  -L./lz4  -o test/split/test_count_rg test/split/test_count_rg.o test/test.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/split/test_expand_format_string.o test/split/test_expand_format_string.c\n",
            "gcc  -L./lz4  -o test/split/test_expand_format_string test/split/test_expand_format_string.o test/test.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/split/test_filter_header_rg.o test/split/test_filter_header_rg.c\n",
            "gcc  -L./lz4  -o test/split/test_filter_header_rg test/split/test_filter_header_rg.o test/test.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/split/test_parse_args.o test/split/test_parse_args.c\n",
            "gcc  -L./lz4  -o test/split/test_parse_args test/split/test_parse_args.o test/test.o libst.a htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "gcc -g -O2 -I. -Ihtslib-1.9 -I./lz4  -c -o test/vcf-miniview.o test/vcf-miniview.c\n",
            "gcc  -L./lz4  -o test/vcf-miniview test/vcf-miniview.o htslib-1.9/libhts.a -lpthread -lz -lm -lbz2 -llzma -lcurl -lcrypto -lz  -lpthread\n",
            "mkdir -p -m 755 /usr/local/bin /usr/local/bin /usr/local/share/man/man1\n",
            "install -p samtools /usr/local/bin\n",
            "install -p misc/ace2sam misc/maq2sam-long misc/maq2sam-short misc/md5fa misc/md5sum-lite misc/wgsim /usr/local/bin\n",
            "install -p misc/blast2sam.pl misc/bowtie2sam.pl misc/export2sam.pl misc/interpolate_sam.pl misc/novo2sam.pl misc/plot-bamstats misc/psl2sam.pl misc/sam2vcf.pl misc/samtools.pl misc/seq_cache_populate.pl misc/soap2sam.pl misc/varfilter.py misc/wgsim_eval.pl misc/zoom2sam.pl /usr/local/bin\n",
            "install -p -m 644 samtools.1 misc/wgsim.1 /usr/local/share/man/man1\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_x9caogNqcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make index\n",
        "![[ -e hg38.genome.fa.fai ]] || samtools faidx hg38.genome.fa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HslrV9F4bsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!samtools merge merged.bam rep1.bam rep2.bam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R47A-Ghu5T9q",
        "colab_type": "code",
        "outputId": "ca86775e-49a6-45e9-f738-3bfc634094c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#generate bedgraph and bw file for positive strand\n",
        "! [[ -e pos_strand.bedGraph ]] || bedtools genomecov -5 -bg -strand + -g hg38.chrom.sizes -ibam merged.bam | sort -k1,1 -k2,2n > pos_strand.bedGraph\n",
        "! [[ -e pos_strand.bw ]] || ./bedGraphToBigWig pos_strand.bedGraph hg38.chrom.sizes pos_strand.bw\n",
        "\n",
        "#generate bedgraph file for negative strand\n",
        "! [[ -e neg_strand.bedGraph ]] || bedtools genomecov -5 -bg -strand - -g hg38.chrom.sizes -ibam merged.bam | sort -k1,1 -k2,2n > neg_strand.bedGraph\n",
        "! [[ -e neg_strand.bw ]] || ./bedGraphToBigWig neg_strand.bedGraph hg38.chrom.sizes neg_strand.bw\n",
        "\n",
        "#generate bedgraph and bw file for control\n",
        "! [[ -e control_pos_strand.bedGraph ]] || bedtools genomecov -5 -bg -strand + -g hg38.chrom.sizes -ibam control.bam | sort -k1,1 -k2,2n > control_pos_strand.bedGraph\n",
        "! [[ -e control_pos_strand.bw ]] || ./bedGraphToBigWig control_pos_strand.bedGraph hg38.chrom.sizes control_pos_strand.bw\n",
        "! [[ -e control_neg_strand.bedGraph ]] || bedtools genomecov -5 -bg -strand - -g hg38.chrom.sizes -ibam control.bam | sort -k1,1 -k2,2n > control_neg_strand.bedGraph\n",
        "! [[ -e control_neg_strand.bw ]] || ./bedGraphToBigWig control_neg_strand.bedGraph hg38.chrom.sizes control_neg_strand.bw"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1991655424 bytes == 0x5622c2b0e000 @  0x7fc4c91c8887 0x5622c0c4453a 0x5622c0c43659 0x5622c0c4413c 0x5622c0c48960 0x5622c0b7eab3 0x7fc4c8267b97 0x5622c0b8348a\n",
            "tcmalloc: large alloc 1937555456 bytes == 0x5622c2b0e000 @  0x7fc4c91c8887 0x5622c0c4453a 0x5622c0c43659 0x5622c0c4413c 0x5622c0c48960 0x5622c0b7eab3 0x7fc4c8267b97 0x5622c0b8348a\n",
            "tcmalloc: large alloc 1586372608 bytes == 0x5622c2b0e000 @  0x7fc4c91c8887 0x5622c0c4453a 0x5622c0c43659 0x5622c0c4413c 0x5622c0c48960 0x5622c0b7eab3 0x7fc4c8267b97 0x5622c0b8348a\n",
            "tcmalloc: large alloc 1991655424 bytes == 0x562628a28000 @  0x7facc61c6887 0x56262726b53a 0x56262726a659 0x56262726b13c 0x56262726f960 0x5626271a5ab3 0x7facc5265b97 0x5626271aa48a\n",
            "tcmalloc: large alloc 1937555456 bytes == 0x562628a28000 @  0x7facc61c6887 0x56262726b53a 0x56262726a659 0x56262726b13c 0x56262726f960 0x5626271a5ab3 0x7facc5265b97 0x5626271aa48a\n",
            "tcmalloc: large alloc 1586372608 bytes == 0x562628a28000 @  0x7facc61c6887 0x56262726b53a 0x56262726a659 0x56262726b13c 0x56262726f960 0x5626271a5ab3 0x7facc5265b97 0x5626271aa48a\n",
            "tcmalloc: large alloc 1991655424 bytes == 0x556ac1882000 @  0x7f32b0f83887 0x556abff8653a 0x556abff85659 0x556abff8613c 0x556abff8a960 0x556abfec0ab3 0x7f32b0022b97 0x556abfec548a\n",
            "tcmalloc: large alloc 1937555456 bytes == 0x556ac1882000 @  0x7f32b0f83887 0x556abff8653a 0x556abff85659 0x556abff8613c 0x556abff8a960 0x556abfec0ab3 0x7f32b0022b97 0x556abfec548a\n",
            "tcmalloc: large alloc 1586372608 bytes == 0x556ac1882000 @  0x7f32b0f83887 0x556abff8653a 0x556abff85659 0x556abff8613c 0x556abff8a960 0x556abfec0ab3 0x7f32b0022b97 0x556abfec548a\n",
            "tcmalloc: large alloc 1991655424 bytes == 0x55562fc1c000 @  0x7f26349c6887 0x55562ef6f53a 0x55562ef6e659 0x55562ef6f13c 0x55562ef73960 0x55562eea9ab3 0x7f2633a65b97 0x55562eeae48a\n",
            "tcmalloc: large alloc 1937555456 bytes == 0x55562fc1c000 @  0x7f26349c6887 0x55562ef6f53a 0x55562ef6e659 0x55562ef6f13c 0x55562ef73960 0x55562eea9ab3 0x7f2633a65b97 0x55562eeae48a\n",
            "tcmalloc: large alloc 1586372608 bytes == 0x55562fc1c000 @  0x7f26349c6887 0x55562ef6f53a 0x55562ef6e659 0x55562ef6f13c 0x55562ef73960 0x55562eea9ab3 0x7f2633a65b97 0x55562eeae48a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lw4rNv3VrNz",
        "colab_type": "code",
        "outputId": "74f6d6c2-0e7d-420a-e9e7-eb931cc3fabc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "![[ -e seqdataloader ]] && rm -rf seqdataloader\n",
        "!git clone https://github.com/kundajelab/seqdataloader.git\n",
        "%cd seqdataloader\n",
        "!pip uninstall seqdataloader\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'seqdataloader'...\n",
            "remote: Enumerating objects: 278, done.\u001b[K\n",
            "remote: Counting objects: 100% (278/278), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 1600 (delta 170), reused 171 (delta 77), pack-reused 1322\u001b[K\n",
            "Receiving objects: 100% (1600/1600), 4.02 MiB | 7.36 MiB/s, done.\n",
            "Resolving deltas: 100% (976/976), done.\n",
            "/content/seqdataloader\n",
            "\u001b[33mWARNING: Skipping seqdataloader as it is not installed.\u001b[0m\n",
            "Processing /content/seqdataloader\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.15) (1.18.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.15) (1.0.3)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.15) (0.29.16)\n",
            "Collecting deeptools>=3.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/34/9964dfaf1dd0977bbb4b0459ce35de87cd1a15f7614773f68434e147dde5/deepTools-3.4.2.tar.gz (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 8.7MB/s \n",
            "\u001b[?25hCollecting pybedtools>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/14/152220f39cda6b9b72810eeed103c6ec78422429adabe3aafc3eaf6feb40/pybedtools-0.8.1.tar.gz (12.5MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyBigWig>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.15) (0.3.17)\n",
            "Requirement already satisfied: pyfaidx in /usr/local/lib/python3.6/dist-packages (from seqdataloader==0.15) (0.5.8)\n",
            "Collecting tiledb>=0.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/93/37f07cbbaa0bf4b797e009e0b057da9bc3dfb0512eea569337e1d981ae83/tiledb-0.5.9-cp36-cp36m-manylinux1_x86_64.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader==0.15) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader==0.15) (2.8.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.15) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.15) (3.2.1)\n",
            "Collecting pysam>=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/01/2be4def91aeb50ccb963879b8193ca667087308696f2fe6aa86c6da9db72/pysam-0.15.4-cp36-cp36m-manylinux2010_x86_64.whl (10.7MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8MB 24.1MB/s \n",
            "\u001b[?25hCollecting numpydoc>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n",
            "Collecting py2bit>=0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/53/bb/547a927bed736ead3dc909e1e552d57c9034bb9493eff80544c0cf6e4828/py2bit-0.3.0.tar.gz\n",
            "Requirement already satisfied: plotly>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader==0.15) (4.4.1)\n",
            "Collecting deeptoolsintervals>=0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/1f/d10d6ad23c86c62d90d867d0506881a392ec6ef06885b858eaab868dd356/deeptoolsintervals-0.1.9.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pybedtools>=0.7->seqdataloader==0.15) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx->seqdataloader==0.15) (46.1.3)\n",
            "Requirement already satisfied: wheel>=0.30 in /usr/local/lib/python3.6/dist-packages (from tiledb>=0.4.4->seqdataloader==0.15) (0.34.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->deeptools>=3.0.1->seqdataloader==0.15) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->deeptools>=3.0.1->seqdataloader==0.15) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->deeptools>=3.0.1->seqdataloader==0.15) (1.2.0)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (1.8.5)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2.11.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader==0.15) (1.3.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (1.2.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (0.7.12)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (0.15.2)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (20.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2.1.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (1.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader==0.15) (1.24.3)\n",
            "Building wheels for collected packages: seqdataloader, deeptools, pybedtools, numpydoc, py2bit, deeptoolsintervals\n",
            "  Building wheel for seqdataloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqdataloader: filename=seqdataloader-0.15-cp36-none-any.whl size=38284 sha256=c293f85842ca5ff8ceeb5c5f0d7c6e28caceaf4dd7ef63ee9acc12d848be86e7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ds242obb/wheels/c2/db/13/112d41662f69fb8c7986c218293570cc1550fc21eed966e31b\n",
            "  Building wheel for deeptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeptools: filename=deepTools-3.4.2-cp36-none-any.whl size=217243 sha256=c48c3b6f4730cdbdbf80566ab7abf64ad6c726e6ab8efd95b6e6563dbca93d26\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/1a/80/0000590b95174acfb1172f405d8e8ddca7c8c23d269c8e1330\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.8.1-cp36-cp36m-linux_x86_64.whl size=13603871 sha256=ca4247c406eaf29faca6f2ee0076f1d62dfaf22af012bf4f2f738464211367b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/50/97/7d0e4f605d0d1578997f4bba3061869c2dee9f8cd29f626323\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31893 sha256=92eedd8134c04b73e5d68557e8f7240d96c8cba6acb17711f12e3cbb1e2e97be\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n",
            "  Building wheel for py2bit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py2bit: filename=py2bit-0.3.0-cp36-cp36m-linux_x86_64.whl size=43537 sha256=8a38709cfd3e5871390cae35fc767909de7c279871607478e5fad6a8ea682eb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/66/b6/33fb9b65b31121127f1da60ca27948ecf8d4c59b0967298de8\n",
            "  Building wheel for deeptoolsintervals (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeptoolsintervals: filename=deeptoolsintervals-0.1.9-cp36-cp36m-linux_x86_64.whl size=108597 sha256=082c52d9de823afaf391e5b2edc518cdd95aaf0025e907b9c6eeb2c8c9c2988a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/60/60/e513c6246f67379f6e1b8d09448cdf913bac3851f96bd42e94\n",
            "Successfully built seqdataloader deeptools pybedtools numpydoc py2bit deeptoolsintervals\n",
            "Installing collected packages: pysam, numpydoc, py2bit, deeptoolsintervals, deeptools, pybedtools, tiledb, seqdataloader\n",
            "Successfully installed deeptools-3.4.2 deeptoolsintervals-0.1.9 numpydoc-0.9.2 py2bit-0.3.0 pybedtools-0.8.1 pysam-0.15.4 seqdataloader-0.15 tiledb-0.5.9\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ZdEGjjwo2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3ff57d58-e81e-4bf6-f23c-91aa67021b92"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neLDnspNt0tb",
        "colab_type": "code",
        "outputId": "65276a7f-0b58-4fdb-e042-06db1c7c53db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "from seqdataloader.batchproducers import coordbased\n",
        "from seqdataloader.batchproducers.coordbased import coordstovals\n",
        "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
        "from seqdataloader.batchproducers.coordbased import coordbatchtransformers\n",
        "\n",
        "seq_len = 1000\n",
        "out_pred_len = 1000\n",
        "\n",
        "inputs_coordstovals = coordstovals.core.CoordsToValsJoiner(\n",
        "    coordstovals_list=[\n",
        "      coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
        "        genome_fasta_path=\"hg38.genome.fa\",\n",
        "        mode_name=\"sequence\",\n",
        "        center_size_to_use=seq_len),\n",
        "      coordstovals.bigwig.PosAndNegSmoothWindowCollapsedLogCounts(\n",
        "        pos_strand_bigwig_path=\"control_pos_strand.bw\",\n",
        "        neg_strand_bigwig_path=\"control_neg_strand.bw\",\n",
        "        counts_mode_name=\"control_logcount\",\n",
        "        profile_mode_name=\"control_profile\",\n",
        "        center_size_to_use=out_pred_len,\n",
        "        smoothing_windows=[1,50])])\n",
        "\n",
        "targets_coordstovals = coordstovals.bigwig.PosAndNegSeparateLogCounts(\n",
        "    pos_strand_bigwig_path=\"pos_strand.bw\",\n",
        "    neg_strand_bigwig_path=\"neg_strand.bw\",\n",
        "    counts_mode_name=\"task0_logcount\",\n",
        "    profile_mode_name=\"task0_profile\",\n",
        "    center_size_to_use=out_pred_len)\n",
        "\n",
        "keras_train_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
        "      bed_file=\"train_1k_around_summits.bed.gz\",\n",
        "      batch_size=64,\n",
        "      shuffle_before_epoch=True, \n",
        "      seed=1234),\n",
        "  inputs_coordstovals=inputs_coordstovals,\n",
        "  targets_coordstovals=targets_coordstovals,\n",
        "  coordsbatch_transformer=coordbatchtransformers.ReverseComplementAugmenter().chain(\n",
        "          coordbatchtransformers.UniformJitter(\n",
        "              maxshift=200, chromsizes_file=\"hg38.chrom.sizes\")))\n",
        "\n",
        "keras_valid_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
        "            bed_file=\"valid_1k_around_summits.bed.gz\",\n",
        "            batch_size=64,\n",
        "            shuffle_before_epoch=False, \n",
        "            seed=1234),\n",
        "  inputs_coordstovals=inputs_coordstovals,\n",
        "  targets_coordstovals=targets_coordstovals)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Pj92bmGDs7",
        "colab_type": "code",
        "outputId": "13f0e1f5-c277-4a83-a900-4bd64d519e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "thebatch = keras_train_batch_generator[0]\n",
        "for tupleidx,tupleentry in enumerate(thebatch):\n",
        "  print(\"Tuple entry\",tupleidx)\n",
        "  for key in tupleentry:\n",
        "    print(key, tupleentry[key].shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tuple entry 0\n",
            "sequence (128, 1000, 4)\n",
            "control_logcount (128,)\n",
            "control_profile (128, 1000, 2)\n",
            "Tuple entry 1\n",
            "task0_logcount (128, 2)\n",
            "task0_profile (128, 1000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngg9bXkBJ8Kn",
        "colab_type": "code",
        "outputId": "11561b43-5774-4c0b-a687-4d00960ac8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "import keras\n",
        "import keras.layers as kl\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "\n",
        "def multinomial_nll(true_counts, logits):\n",
        "    \"\"\"Compute the multinomial negative log-likelihood\n",
        "    Args:\n",
        "      true_counts: observed count values\n",
        "      logits: predicted logit values\n",
        "    \"\"\"\n",
        "    counts_per_example = tf.reduce_sum(true_counts, axis=-1)\n",
        "    dist = tfp.distributions.Multinomial(total_count=counts_per_example,\n",
        "                                         logits=logits)\n",
        "    return (-tf.reduce_sum(dist.log_prob(true_counts)) / \n",
        "            tf.to_float(tf.shape(true_counts)[0]))\n",
        "\n",
        "\n",
        "#from https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/losses.py#L87\n",
        "class MultichannelMultinomialNLL(object):\n",
        "    def __init__(self, n):\n",
        "        self.__name__ = \"MultichannelMultinomialNLL\"\n",
        "        self.n = n\n",
        "\n",
        "    def __call__(self, true_counts, logits):\n",
        "        for i in range(self.n):\n",
        "            loss = multinomial_nll(true_counts[..., i], logits[..., i])\n",
        "            if i == 0:\n",
        "                total = loss\n",
        "            else:\n",
        "                total += loss\n",
        "        return total\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"n\": self.n}\n",
        "\n",
        "\n",
        "#model architecture is based on \n",
        "#https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/basepair/models.py#L534\n",
        "#The non-cli parameters are specified in:\n",
        "# https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/src/chipnexus/train/seqmodel/joint-model-valid.gin\n",
        "#The cli parameters are in line 165 of:\n",
        "# https://docs.google.com/spreadsheets/d/1n3l2HXKSNpmNUOifD41uRzDEAgmOqXMQDxquRaz6WLg/edit#gid=0\n",
        "# which seems to match https://github.com/kundajelab/basepair/blob/cda0875571066343cdf90aed031f7c51714d991a/src/chipnexus/train/seqmodel/ChIP-seq-default.gin\n",
        "#Some defaults have been changed to match https://github.com/kundajelab/yeastvar/blob/master/trainModel.py\n",
        "\n",
        "def get_keras_model(seq_len, out_pred_len, c_task_weight,\n",
        "                    filters=64,\n",
        "                    n_dil_layers=6,\n",
        "                    conv1_kernel_size=21,\n",
        "                    tconv_kernel_size=75,\n",
        "                    lr=0.004):\n",
        "    inp = kl.Input(shape=(seq_len, 4), name='sequence')\n",
        "    first_conv = kl.Conv1D(filters,\n",
        "                           kernel_size=conv1_kernel_size,\n",
        "                           padding='same',\n",
        "                           activation='relu')(inp)\n",
        "    bias_counts_input = kl.Input(shape=(1, ), name=\"control_logcount\")\n",
        "    bias_profile_input = kl.Input(shape=(out_pred_len, 2), name=\"control_profile\")\n",
        "\n",
        "    prev_layers = [first_conv]\n",
        "    for i in range(1, n_dil_layers + 1):\n",
        "      if i == 1:\n",
        "          prev_sum = first_conv\n",
        "      else:\n",
        "          prev_sum = kl.add(prev_layers)\n",
        "\n",
        "      conv_output = kl.Conv1D(filters, kernel_size=3, padding='same',\n",
        "                              activation='relu', dilation_rate=2**i)(prev_sum)\n",
        "      prev_layers.append(conv_output)\n",
        "\n",
        "    combined_conv = kl.add(prev_layers)\n",
        "\n",
        "    #Counts prediction\n",
        "    gap_combined_conv = kl.GlobalAvgPool1D()(combined_conv)\n",
        "    count_out = kl.Dense(2, name=\"task0_logcount\")(\n",
        "        kl.concatenate([gap_combined_conv, bias_counts_input], axis=-1))\n",
        "    \n",
        "    # De-conv for profile prediction\n",
        "    # reshape needed cos feeding to Conv2DTranspose\n",
        "    reshaped_combined_conv = kl.Reshape((-1, 1, filters))(combined_conv)\n",
        "    reshaped_conv_truncate = keras.layers.Lambda(\n",
        "        lambda x: x[:, int(seq_len/2)-int(out_pred_len/2):\n",
        "                       int(seq_len/2)+int(out_pred_len/2), :, :],\n",
        "        output_shape=(out_pred_len,1,filters))(reshaped_combined_conv)\n",
        "    profile_out_prebias = kl.Reshape((-1, 2))(\n",
        "        kl.Conv2DTranspose(2,\n",
        "                           kernel_size=(tconv_kernel_size, 1),\n",
        "                           padding='same')(reshaped_conv_truncate))\n",
        "    profile_out = kl.Conv1D(2, kernel_size=1,\n",
        "                            name=\"task0_profile\")(\n",
        "                    kl.concatenate([profile_out_prebias,\n",
        "                                    bias_profile_input], axis=-1))\n",
        "\n",
        "  \n",
        "    model = keras.models.Model(\n",
        "      inputs=[inp, bias_counts_input, bias_profile_input],\n",
        "      outputs=[count_out, profile_out])\n",
        "    model.compile(keras.optimizers.Adam(lr=lr),\n",
        "                  loss=['mse', MultichannelMultinomialNLL(2)],\n",
        "                  loss_weights=[c_task_weight, 1])\n",
        "    return model\n",
        "\n",
        "model = get_keras_model(seq_len=seq_len, out_pred_len=out_pred_len,\n",
        "                        c_task_weight=100)\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
        "                            patience=5, restore_best_weights=True)\n",
        "loss_history = model.fit_generator(keras_train_batch_generator,\n",
        "                    epochs=200,\n",
        "                    validation_data=keras_valid_batch_generator,\n",
        "                    callbacks=[early_stopping_callback])\n",
        "model.set_weights(early_stopping_callback.best_weights)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-4-0919852d6dd3>:17: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "696/696 [==============================] - 204s 294ms/step - loss: 531.7466 - task0_logcount_loss: 1.0660 - task0_profile_loss: 425.1429 - val_loss: 444.8646 - val_task0_logcount_loss: 0.5565 - val_task0_profile_loss: 389.2186\n",
            "Epoch 2/200\n",
            "696/696 [==============================] - 167s 240ms/step - loss: 397.9281 - task0_logcount_loss: 0.5402 - task0_profile_loss: 343.9049 - val_loss: 419.4659 - val_task0_logcount_loss: 0.5505 - val_task0_profile_loss: 364.4196\n",
            "Epoch 3/200\n",
            "696/696 [==============================] - 168s 241ms/step - loss: 387.6185 - task0_logcount_loss: 0.4882 - task0_profile_loss: 338.8032 - val_loss: 412.8784 - val_task0_logcount_loss: 0.4774 - val_task0_profile_loss: 365.1361\n",
            "Epoch 4/200\n",
            "696/696 [==============================] - 169s 243ms/step - loss: 380.6612 - task0_logcount_loss: 0.4520 - task0_profile_loss: 335.4577 - val_loss: 401.3583 - val_task0_logcount_loss: 0.4405 - val_task0_profile_loss: 357.3082\n",
            "Epoch 5/200\n",
            "  7/696 [..............................] - ETA: 3:56 - loss: 389.1287 - task0_logcount_loss: 0.4519 - task0_profile_loss: 343.9352"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfcslLnFCJ1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "keras_test_batch_generator = coordbased.core.KerasBatchGenerator(\n",
        "  coordsbatch_producer=coordbatchproducers.SimpleCoordsBatchProducer(\n",
        "            bed_file=\"test_1k_around_summits.bed.gz\",\n",
        "            batch_size=64,\n",
        "            shuffle_before_epoch=False, \n",
        "            seed=1234),\n",
        "  inputs_coordstovals=inputs_coordstovals,\n",
        "  targets_coordstovals=targets_coordstovals)\n",
        "\n",
        "test_preds_logcount = []\n",
        "test_biastrack_logcount = []\n",
        "test_biastrack_profile = []\n",
        "test_seqs = []\n",
        "test_preds_profile = []\n",
        "test_labels_logcount = []\n",
        "test_labels_profile = []\n",
        "for batch_idx in range(len(keras_test_batch_generator)):\n",
        "    batch_inputs, batch_labels = keras_test_batch_generator[batch_idx]\n",
        "    test_seqs.append(batch_inputs['sequence'])\n",
        "    test_biastrack_logcount.append(batch_inputs['control_logcount'])\n",
        "    test_biastrack_profile.append(batch_inputs['control_profile'])\n",
        "    test_preds = model.predict(batch_inputs)\n",
        "    test_preds_logcount.append(test_preds[0])\n",
        "    test_preds_profile.append(test_preds[1])\n",
        "    test_labels_logcount.append(batch_labels['task0_logcount'])\n",
        "    test_labels_profile.append(batch_labels['task0_profile'])\n",
        "test_biastrack_logcount = np.concatenate(test_biastrack_logcount, axis=0)\n",
        "test_biastrack_profile = np.concatenate(test_biastrack_profile,axis=0)\n",
        "test_seqs = np.concatenate(test_seqs,axis=0)\n",
        "test_preds_logcount = np.concatenate(test_preds_logcount, axis=0)\n",
        "test_preds_profile = np.concatenate(test_preds_profile, axis=0)\n",
        "test_labels_logcount = np.concatenate(test_labels_logcount, axis=0)\n",
        "test_labels_profile = np.concatenate(test_labels_profile, axis=0)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "test_labels_logtotalcount = np.log(np.sum(np.exp(test_labels_logcount) - 1,axis=-1) + 1)\n",
        "\n",
        "plt.scatter(test_biastrack_logcount, test_labels_logtotalcount, alpha=0.1)\n",
        "plt.xlabel(\"Bias track log counts\")\n",
        "plt.ylabel(\"True log total counts\")\n",
        "plt.plot([np.min(test_biastrack_logcount), np.max(test_biastrack_logcount)],\n",
        "         [np.min(test_biastrack_logcount), np.max(test_biastrack_logcount)],\n",
        "         color=\"black\")\n",
        "plt.show()\n",
        "print(spearmanr(test_biastrack_logcount, test_labels_logtotalcount))\n",
        "\n",
        "\n",
        "#do a scatterplot of total count predictions\n",
        "plt.scatter(test_preds_logcount[:,0], test_labels_logcount[:,0], alpha=0.1)\n",
        "plt.xlabel(\"Predicted log counts - Forward Strand\")\n",
        "plt.ylabel(\"True log counts - Forward Strand\")\n",
        "plt.plot([np.min(test_preds_logcount[:,0]), np.max(test_preds_logcount[:,0])],\n",
        "         [np.min(test_preds_logcount[:,0]), np.max(test_preds_logcount[:,0])],\n",
        "         color=\"black\")\n",
        "plt.show()\n",
        "print(spearmanr(test_preds_logcount[:,0], test_labels_logcount[:,0]))\n",
        "\n",
        "plt.scatter(test_preds_logcount[:,1], test_labels_logcount[:,1], alpha=0.1)\n",
        "plt.xlabel(\"Predicted log counts - Reverse Strand\")\n",
        "plt.ylabel(\"True log counts - Reverse Strand\")\n",
        "plt.plot([np.min(test_preds_logcount[:,1]), np.max(test_preds_logcount[:,1])],\n",
        "         [np.min(test_preds_logcount[:,1]), np.max(test_preds_logcount[:,1])],\n",
        "         color=\"black\")\n",
        "plt.show()\n",
        "print(spearmanr(test_preds_logcount[:,1], test_labels_logcount[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY7mDAU2kXGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install deeplift\n",
        "from deeplift.util import compile_func"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8VoHRg-kdBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from deeplift.visualization import viz_sequence\n",
        "from matplotlib.ticker import FormatStrFormatter\n",
        "\n",
        "gradtensor = tf.gradients(ys=tf.reduce_sum(model.outputs[0],1),\n",
        "                          xs=model.inputs[0])[0]\n",
        "gradfunc = compile_func(inputs=model.inputs, outputs=gradtensor)\n",
        "\n",
        "sorted_test_indices = [x[0] for x in \n",
        "                       sorted(enumerate(test_labels_logtotalcount),\n",
        "                              key=lambda x: -x[1])]\n",
        "\n",
        "def smooth(vals):\n",
        "  return np.convolve(vals, np.ones(1,)/1, mode='same')\n",
        "\n",
        "for idx in sorted_test_indices[:10]: \n",
        "  true_profile = test_labels_profile[idx] \n",
        "  print(\"idx\",idx)\n",
        "  print(\"Counts\",np.sum(true_profile,axis=0) )\n",
        "  print(\"Predcounts\",np.exp(test_preds_logcount[idx])-1)\n",
        "\n",
        "  for oneovertemp in [1.0]:\n",
        "      print(\"oneovertemp\",oneovertemp)\n",
        "      print(test_labels_profile[idx].shape)\n",
        "      print(\"Pred profile shape\", test_preds_profile[idx].shape)\n",
        "      pred_profile = (np.sum(test_labels_profile[idx], axis=0)[None,:] #total counts\n",
        "                      *(np.exp(test_preds_profile[idx]*oneovertemp)/\n",
        "                        np.sum(np.exp(test_preds_profile[idx]*oneovertemp),axis=0)[None,:]) )   \n",
        "      plt.figure(figsize=(20,2))\n",
        "      \n",
        "      plt.plot(np.arange(0,1000), smooth(true_profile[:,0]), alpha=0.3)\n",
        "      plt.plot(np.arange(0,1000), -smooth(true_profile[:,1]), alpha=0.3)\n",
        "      plt.plot(np.arange(0,1000), pred_profile[:,0])\n",
        "      plt.plot(np.arange(0,1000), -pred_profile[:,1])\n",
        "      plt.xlim(0,1000)\n",
        "      plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
        "      plt.show()\n",
        "      \n",
        "  seqs_to_explain = test_seqs[idx:idx+1]\n",
        "  control_logcounts = test_biastrack_logcount[idx:idx+1][:,None]\n",
        "  control_profiles = test_biastrack_profile[idx:idx+1]\n",
        "\n",
        "  explanation = gradfunc([seqs_to_explain,\n",
        "                          control_logcounts,\n",
        "                          control_profiles])*seqs_to_explain\n",
        "  plt.figure(figsize=(20,2))\n",
        "  plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.4f'))\n",
        "  viz_sequence.plot_weights_given_ax(ax=plt.gca(),\n",
        "                                     array=explanation[0],\n",
        "                                     height_padding_factor=0.2,\n",
        "                                     length_padding=1.0,\n",
        "                                     highlight={},\n",
        "                                     subticks_frequency=100)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmh388y6LXiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"MyProfileModel.h5\")\n",
        "\n",
        "#to reload, you need to set up a CustomObjectScope\n",
        "from keras.utils import CustomObjectScope\n",
        "from keras.models import load_model\n",
        "with CustomObjectScope({'MultichannelMultinomialNLL': MultichannelMultinomialNLL}):\n",
        "  loaded_model = load_model('MyProfileModel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiBrEOsw3MBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}