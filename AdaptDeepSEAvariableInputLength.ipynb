{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaptDeepSEAvariableInputLength.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvantiShri/colab_notebooks/blob/master/AdaptDeepSEAvariableInputLength.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqd5DWDcs-n2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9cab4cfe-eb5e-4b27-f2fe-c17c44f7793b"
      },
      "source": [
        "!wget http://mitra.stanford.edu/kundaje/avanti/deepsea_beluga/deepseabeluga_keras.h5 -O deepseabeluga_keras.h5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-08 18:05:03--  http://mitra.stanford.edu/kundaje/avanti/deepsea_beluga/deepseabeluga_keras.h5\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 598195356 (570M)\n",
            "Saving to: ‘deepseabeluga_keras.h5’\n",
            "\n",
            "deepseabeluga_keras 100%[===================>] 570.48M  14.1MB/s    in 31s     \n",
            "\n",
            "2019-10-08 18:05:34 (18.6 MB/s) - ‘deepseabeluga_keras.h5’ saved [598195356/598195356]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYIiIBRUuvn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82c2db68-5466-4224-be3c-a77232588586"
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"deepseabeluga_keras.h5\")\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 1993, 320)         10560     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1993, 320)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1986, 320)         819520    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1986, 320)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1986, 320)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 496, 320)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 489, 480)          1229280   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 489, 480)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 482, 480)          1843680   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 482, 480)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 482, 480)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 120, 480)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 113, 640)          2458240   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 113, 640)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 106, 640)          3277440   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 106, 640)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 106, 640)          0         \n",
            "_________________________________________________________________\n",
            "permute_1 (Permute)          (None, 640, 106)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 67840)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2003)              135885523 \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 2003)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2002)              4012008   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 2002)              0         \n",
            "=================================================================\n",
            "Total params: 149,536,251\n",
            "Trainable params: 149,536,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgMS6Yhju37m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense,Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "\n",
        "new_model = Sequential()\n",
        "#Different first layer with input_shape=(400,4) instead of (2000,4)\n",
        "new_model.add(Conv1D(kernel_size=8, filters=320, input_shape=(400,4)))\n",
        "new_model.layers[0].set_weights(model.layers[0].get_weights())\n",
        "#We copy over remaining layers up until the Permute layer, which we are\n",
        "# going to get rid of the need for (I had the Permute layer to cope\n",
        "# with the fact that the original pytorch model was in a 'channels first'\n",
        "# format, but Keras is 'channels last', and the weights of the pytorch Dense\n",
        "# layer were such that it was expecting the output of the conv layer to\n",
        "# be in a 'channels first' format - however, we will deal with this by\n",
        "# just rearranging the weights of the Dense layer, since we have to modify\n",
        "# those weights anyway).\n",
        "for layer in model.layers[1:16]:\n",
        "  layer_config = layer.get_config()\n",
        "  del layer_config['name'] #let the name be autogenerated to avoid collisions\n",
        "  new_layer = type(layer)(**layer_config)\n",
        "  if (len(layer.get_weights()) > 0):\n",
        "      new_layer.build(layer.input_shape)\n",
        "  new_layer.set_weights(layer.get_weights())\n",
        "  new_model.add(new_layer)\n",
        "new_model.add(Flatten())\n",
        "new_model.add(Dense(2003,name=\"altereddense\"))\n",
        "for layer in model.layers[20:]:\n",
        "  layer_config = layer.get_config()\n",
        "  del layer_config['name'] #let the name be autogenerated to avoid collisions\n",
        "  new_layer = type(layer)(**layer_config)\n",
        "  if (len(layer.get_weights()) > 0):\n",
        "      new_layer.build(layer.input_shape)\n",
        "  new_layer.set_weights(layer.get_weights())\n",
        "  new_model.add(new_layer)\n",
        "\n",
        "first_dense_layer_weights, first_dense_layer_biases = model.layers[19].get_weights()\n",
        "#These next lines alter the weights of the dense layer so that the whole model\n",
        "# will work on an input of length 400bp\n",
        "#While porting the weights over, we also get rid of the need for the Permute\n",
        "# layer by applying the 'transpose' on the weights. The truncation of 50:56 is\n",
        "# what gets the model to work on an input of length 400bp\n",
        "new_first_dense_layer_weights = first_dense_layer_weights.reshape((640,106,2003))[:,50:56,:].transpose((1,0,2)).reshape((3840,2003))\n",
        "new_model.layers[17].set_weights([new_first_dense_layer_weights, first_dense_layer_biases])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwXpOOHgvQke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "random_inputs = np.random.RandomState(1).rand(20,2000,4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ6R7vgevRVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.core import Permute, Flatten\n",
        "\n",
        "#the output of new_model should be the same as if we took the original model,\n",
        "# but artificially set the activations on the flanks of the last conv layer\n",
        "# to zero for neurons with a receptive field that extended outside the central\n",
        "# 400bp. We test that here.\n",
        "orig_model_last_conv_out_model = Model(inputs=model.input,\n",
        "                                 outputs=model.layers[16].output)\n",
        "last_bit_of_model = Sequential()\n",
        "last_bit_of_model.add(Permute(dims=(2,1), input_shape=(106,640)))\n",
        "for layer in model.layers[18:]:\n",
        "  last_bit_of_model.add(layer)\n",
        "\n",
        "orig_model_last_conv_out = orig_model_last_conv_out_model.predict(random_inputs)\n",
        "orig_model_last_conv_out[:,0:50,:] = 0.0\n",
        "orig_model_last_conv_out[:,56:,:] = 0.0\n",
        "zerodflanks_orig_model_out = last_bit_of_model.predict(orig_model_last_conv_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCRw0TiIv8QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_preds = new_model.predict(random_inputs[:,800:1200,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKc1HOAGwT8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5dea92bd-9395-4615-d3df-8c0e72c09578"
      },
      "source": [
        "np.max(np.abs(zerodflanks_orig_model_out-new_preds))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1920929e-07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foPoQ8RpzQNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "c862b800-41d6-4c40-ff65-a6d3e5456bce"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 393, 320)          10560     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 393, 320)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 386, 320)          819520    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 386, 320)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 386, 320)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 96, 320)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 89, 480)           1229280   \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 89, 480)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 82, 480)           1843680   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 82, 480)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 82, 480)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 20, 480)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 13, 640)           2458240   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 13, 640)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 6, 640)            3277440   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 6, 640)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3840)              0         \n",
            "_________________________________________________________________\n",
            "altereddense (Dense)         (None, 2003)              7693523   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 2003)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2002)              4012008   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 2002)              0         \n",
            "=================================================================\n",
            "Total params: 21,344,251\n",
            "Trainable params: 21,344,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6K71dg07dzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}